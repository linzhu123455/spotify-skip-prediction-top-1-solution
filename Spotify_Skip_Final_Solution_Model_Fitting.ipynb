{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import hickle as hkl\n",
    "from numpy import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D, Dense, Embedding\n",
    "from keras.layers import concatenate, Input, LSTM, GRU, merge, Lambda, Dot, Add, Multiply, \\\n",
    "wrappers, Dropout, GlobalAveragePooling1D, Bidirectional, BatchNormalization, Activation\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Reshape\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import LSTM, Dense\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\n",
    "\n",
    "import keras.backend as KTF\n",
    "import tensorflow as tf\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "KTF.set_session(sess)\n",
    "\n",
    "data_path = 'Skip_Data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.20.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 1500 # skip_net_glove_max_mtsk_more_layer_best\n",
    "\n",
    "batch_size = 3000 # skip_net_glove_max_mtsk_more_layer_best_v2\n",
    "\n",
    "batch_size = 3000 # skip_net_glove_max_mtsk_more_layer_best_bn\n",
    "\n",
    "batch_size = 2200 # skip_net_glove_max_mtsk_more_layer_best_v3\n",
    "\n",
    "batch_size = 2200 # skip_net_glove_max_mtsk_more_layer_best_v4\n",
    "\n",
    "data_path = 'Skip_Data/'\n",
    "\n",
    "le_track_id = joblib.load('le_track_id.pkl')\n",
    "\n",
    "spotify_song_fea = pd.read_parquet('spotify_song_fea.parquet')\n",
    "\n",
    "le = LabelEncoder()\n",
    "##\n",
    "spotify_song_fea['mode'] = le.fit_transform(spotify_song_fea['mode'])\n",
    "\n",
    "track_id = np.array(spotify_song_fea['track_id'])\n",
    "\n",
    "cols_to_be_normalized = ['duration', 'release_year', 'us_popularity_estimate',\n",
    "       'acousticness', 'beat_strength', 'bounciness', 'danceability',\n",
    "       'dyn_range_mean', 'energy', 'flatness', 'instrumentalness', 'key',\n",
    "       'liveness', 'loudness', 'mechanism', 'mode', 'organism', 'speechiness',\n",
    "       'tempo', 'time_signature', 'valence', 'acoustic_vector_0',\n",
    "       'acoustic_vector_1', 'acoustic_vector_2', 'acoustic_vector_3',\n",
    "       'acoustic_vector_4', 'acoustic_vector_5', 'acoustic_vector_6',\n",
    "       'acoustic_vector_7']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "spotify_song_array = scaler.fit_transform(spotify_song_fea[cols_to_be_normalized])\n",
    "\n",
    "order = np.argsort(track_id)\n",
    "spotify_song_array = spotify_song_array[order,:]\n",
    "\n",
    "song_zero_embedding = -2*np.ones((1,spotify_song_array.shape[1]))\n",
    "spotify_song_array = np.concatenate((song_zero_embedding,spotify_song_array),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.20.1 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "\n",
    "batch_size = 1500 # skip_net_glove_max_mtsk_more_layer_best\n",
    "\n",
    "batch_size = 3000 # skip_net_glove_max_mtsk_more_layer_best_v2\n",
    "\n",
    "batch_size = 3000 # skip_net_glove_max_mtsk_more_layer_best_bn\n",
    "\n",
    "data_path = 'Skip_Data/'\n",
    "\n",
    "le_track_id = joblib.load('le_track_id.pkl')\n",
    "\n",
    "spotify_song_fea = pd.read_parquet('spotify_song_fea.parquet')\n",
    "\n",
    "le = LabelEncoder()\n",
    "##\n",
    "spotify_song_fea['mode'] = le.fit_transform(spotify_song_fea['mode'])\n",
    "\n",
    "track_id = np.array(spotify_song_fea['track_id'])\n",
    "\n",
    "spotify_song_fea['duration'] = spotify_song_fea['duration']/100\n",
    "spotify_song_fea['release_year'] = spotify_song_fea['release_year']-1950\n",
    "spotify_song_fea['us_popularity_estimate'] = spotify_song_fea['us_popularity_estimate'] - 90\n",
    "\n",
    "spotify_song_fea['duration_05'] = spotify_song_fea['duration']**0.5\n",
    "spotify_song_fea['duration_15'] = spotify_song_fea['duration']**1.5\n",
    "spotify_song_fea['duration_2'] = spotify_song_fea['duration']**2\n",
    "spotify_song_fea['duration_3'] = spotify_song_fea['duration']**3\n",
    "\n",
    "spotify_song_fea['release_year_05'] = spotify_song_fea['release_year']**0.5\n",
    "spotify_song_fea['release_year_15'] = spotify_song_fea['release_year']**1.5\n",
    "spotify_song_fea['release_year_2'] = spotify_song_fea['release_year']**2\n",
    "spotify_song_fea['release_year_3'] = spotify_song_fea['release_year']**3\n",
    "\n",
    "spotify_song_fea['us_popularity_estimate_15'] = spotify_song_fea['us_popularity_estimate']**1.5\n",
    "spotify_song_fea['us_popularity_estimate_2'] = spotify_song_fea['us_popularity_estimate']**2\n",
    "spotify_song_fea['us_popularity_estimate_3'] = spotify_song_fea['us_popularity_estimate']**3\n",
    "\n",
    "cols_to_be_normalized = ['us_popularity_estimate_3', 'us_popularity_estimate_2', 'us_popularity_estimate_15', 'release_year_05','release_year_15','release_year_2','duration_05','duration_15','duration_2','duration', 'release_year', 'us_popularity_estimate',\n",
    "       'acousticness', 'beat_strength', 'bounciness', 'danceability',\n",
    "       'dyn_range_mean', 'energy', 'flatness', 'instrumentalness', 'key',\n",
    "       'liveness', 'loudness', 'mechanism', 'mode', 'organism', 'speechiness',\n",
    "       'tempo', 'time_signature', 'valence', 'acoustic_vector_0',\n",
    "       'acoustic_vector_1', 'acoustic_vector_2', 'acoustic_vector_3',\n",
    "       'acoustic_vector_4', 'acoustic_vector_5', 'acoustic_vector_6',\n",
    "       'acoustic_vector_7']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "spotify_song_array = scaler.fit_transform(spotify_song_fea[cols_to_be_normalized])\n",
    "\n",
    "order = np.argsort(track_id)\n",
    "spotify_song_array = spotify_song_array[order,:]\n",
    "\n",
    "song_zero_embedding = -2*np.ones((1,spotify_song_array.shape[1]))\n",
    "spotify_song_array = np.concatenate((song_zero_embedding,spotify_song_array),axis=0)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Glove Embedding\n",
    "\n",
    "spotify_song_array_glove = hkl.load('song_embedding_matrix_150.hkl')\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "spotify_song_array = np.concatenate((spotify_song_array,spotify_song_array_glove),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3706389, 179)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the previous steps are done correctly, the embedding matrix should be of size (3706389, 179)\n",
    "\n",
    "spotify_song_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Skip_Data/le_reason_end.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.externals import joblib\n",
    "#joblib.dump(le_context_type, data_path+'le_context_type.pkl')\n",
    "#joblib.dump(le_reason_start, data_path+'le_reason_start.pkl')\n",
    "#joblib.dump(le_reason_end, data_path+'le_reason_end.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_context_type = joblib.load(data_path+'le_context_type.pkl')\n",
    "le_reason_start = joblib.load(data_path+'le_reason_start.pkl')\n",
    "le_reason_end = joblib.load(data_path+'le_reason_end.pkl')\n",
    "\n",
    "n_context_type = len(le_context_type.classes_) + 1\n",
    "n_reason_start = len(le_reason_start.classes_) + 1\n",
    "n_reason_end = len(le_reason_end.classes_) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For v5\n",
    "\n",
    "elements = [-2,-1,0,1,2]\n",
    "probabilities = [0.1,0.25,0.3,0.25,0.1]\n",
    "#np.random.choice(elements, 10, p=probabilities)\n",
    "\n",
    "def ProcessSessionCate(df, if_gen = 0, batch_size = batch_size, sample = 0):\n",
    "     df['date'] = pd.to_datetime(df['date'] )\n",
    "        \n",
    "    df['date_gap'] = df['date'] - pd.Timestamp(2018, 7, 13)\n",
    "    df['date_gap'] = df['date_gap'].dt.days\n",
    "    \n",
    "    \n",
    "    df['context_type'] = le_context_type.transform(df['context_type'])\n",
    "    df['hist_user_behavior_reason_start'] = le_reason_start.transform(df['hist_user_behavior_reason_start'])\n",
    "    df['hist_user_behavior_reason_end'] = le_reason_end.transform(df['hist_user_behavior_reason_end'])\n",
    "    session_cols = ['session_id', 'session_position', 'session_length', 'track_id_clean',\n",
    "                    'skip_1', 'skip_2', 'skip_3', 'not_skipped', 'context_switch',\n",
    "                    'no_pause_before_play', 'short_pause_before_play',\n",
    "                    'long_pause_before_play', 'hist_user_behavior_n_seekfwd',\n",
    "                    'hist_user_behavior_n_seekback', 'hist_user_behavior_is_shuffle',\n",
    "                    'hour_of_day', 'premium', 'context_type',\n",
    "                    'hist_user_behavior_reason_start', 'hist_user_behavior_reason_end','date_gap']\n",
    "    \n",
    "    session_id = np.unique(df['session_id'])    \n",
    "    session_position_offset = np.random.choice(elements, len(session_id), p=probabilities)\n",
    "    df_offset = pd.DataFrame()\n",
    "    df_offset['session_id'] = session_id\n",
    "    if sample == 1:\n",
    "        df_offset['session_position_offset'] = session_position_offset\n",
    "    else:\n",
    "        df_offset['session_position_offset'] = 0\n",
    "        \n",
    "    n0 = df.shape[0]\n",
    "        \n",
    "    df = pd.merge(df, df_offset, on = 'session_id', how = 'left')\n",
    "    df['session_position'] = df['session_position'] + df['session_position_offset']\n",
    "    df = df[df['session_position']<=df['session_length']].reset_index(drop=True)\n",
    "    df = df[df['session_position']>=1].reset_index(drop=True)\n",
    "    \n",
    "    n1 = df.shape[0]\n",
    "    \n",
    "    #print('shrinkage:',n0, n1)\n",
    "\n",
    "    df['track_id_clean'] = df['track_id_clean'] + 1\n",
    "    df['hour_of_day'] = df['hour_of_day']/24\n",
    "\n",
    "    raw_data = np.array(df[session_cols].values) * 1\n",
    "    raw_data = raw_data.astype(np.float)\n",
    "\n",
    "    input_raw_data = raw_data[raw_data[:,1] * 2 <= raw_data[:, 2], :]\n",
    "    output_raw_data = raw_data[raw_data[:,1] * 2 > raw_data[:, 2], :]\n",
    "\n",
    "    input_raw_data_final_p = np.floor(input_raw_data[:, 2] / 2).astype(np.int)\n",
    "    input_raw_data_final_p = 10 - input_raw_data_final_p + input_raw_data[:, 1]\n",
    "\n",
    "    output_raw_data_first_p = np.floor(output_raw_data[:, 2] / 2).astype(np.int)\n",
    "    output_raw_data_first_p = -output_raw_data_first_p + output_raw_data[:, 1]\n",
    "\n",
    "    n_session = int(np.max(raw_data[:,0])) + 1\n",
    "    gc.collect()\n",
    "    input_data = -2 * np.ones((n_session * 10, 18))\n",
    "    output_data = -2 * np.ones((n_session * 10, 19))\n",
    "\n",
    "    input_data[:, 17] = n_reason_end - 1\n",
    "    output_data[:, 17] = n_reason_end - 1\n",
    "    \n",
    "    input_data[:, 16] = n_reason_start - 1\n",
    "    output_data[:, 16] = n_reason_start - 1\n",
    "    \n",
    "    input_data[:, 15] = n_context_type - 1\n",
    "    output_data[:, 15] = n_context_type - 1\n",
    "    \n",
    "    '''    \n",
    "    output_premium = input_data[:,9,14]    \n",
    "    output_premium = np.reshape(output_premium,(len(output_premium),1,1))\n",
    "    output_premium = np.tile(output_premium,(1,10,1))\n",
    "    '''\n",
    "    \n",
    "    input_raw_data[:,2] = input_raw_data[:,1]/input_raw_data[:,2]\n",
    "    output_raw_data[:,2] = output_raw_data[:,1]/output_raw_data[:,2]\n",
    "\n",
    "\n",
    "    input_data[input_raw_data[:, 0].astype(np.int) * 10 + input_raw_data_final_p.astype(np.int) - 1,\n",
    "    :] = input_raw_data[:, 2:20]\n",
    "    output_data[output_raw_data[:, 0].astype(np.int) * 10 + output_raw_data_first_p.astype(np.int) - 1,\n",
    "    :] = output_raw_data[:, 2:21]\n",
    "    input_data = np.reshape(input_data, (n_session, 10, input_data.shape[1]))\n",
    "    output_data = np.reshape(output_data, (n_session, 10, output_data.shape[1]))\n",
    "    output_data_target = output_data[:, :, 2:13]\n",
    "    output_data_target[output_data_target>1] = 1\n",
    "    output_data_target[output_data_target < 0] = 0\n",
    "    \n",
    "    output_date_id = output_data[:, :, 18]\n",
    "    \n",
    "    #output_data_target[:,:,3] = 1 - output_data_target[:,:,1]   \n",
    "    \n",
    "    output_data_id = output_data[:,:,1]\n",
    "\n",
    "    order = np.arange(n_session)\n",
    "    random.shuffle(order)\n",
    "    \n",
    "    if if_gen == 1:\n",
    "        order = order[0:int(batch_size*np.floor(n_session/batch_size))]        \n",
    "\n",
    "    input_data = input_data[order,:,:]  \n",
    " \n",
    "    input_data_context_id = input_data[:,:,15]\n",
    "    input_data_start_id = input_data[:,:,16]\n",
    "    input_data_end_id = input_data[:,:,17]\n",
    "\n",
    "    input_data = input_data[:,:,range(15)]\n",
    "\n",
    "    input_data_id = input_data[:,:,1]\n",
    "    input_data = np.delete(input_data, 1, 2)\n",
    "    output_data_id = output_data_id[order,:]\n",
    "    output_data_target = output_data_target[order,:]\n",
    "    \n",
    "    output_data = output_data[:,:,0]\n",
    "    \n",
    "    input_data_context_id[input_data_context_id<0] = 0\n",
    "    input_data_start_id[input_data_start_id<0] = 0\n",
    "    input_data_end_id[input_data_end_id<0] = 0\n",
    "    input_data_id[input_data_id<0] = 0\n",
    "    output_data_id[output_data_id<0] = 0\n",
    "    \n",
    "    input_data_context_id = input_data_context_id.astype(int)\n",
    "    input_data_start_id = input_data_start_id.astype(int)\n",
    "    input_data_end_id = input_data_end_id.astype(int)\n",
    "    input_data_id = input_data_id.astype(int)\n",
    "    output_data_id = output_data_id.astype(int)\n",
    "\n",
    "    return input_data, output_data, input_data_context_id, input_data_start_id, input_data_end_id,\\\n",
    "           input_data_id, output_data_id, output_data_target, output_date_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the train and validation files.\n",
    "train_files = glob.glob(data_path + '*.csv.parquet')\n",
    "len(train_files)\n",
    "valid_files = ['Skip_Data/log_0_20180715_000000000000.csv.parquet']\n",
    "train_files = list(set(train_files)-set(valid_files))\n",
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Skip_Data/log_9_20180718_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180825_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180914_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180815_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180906_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180916_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180726_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180824_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180825_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180803_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180829_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180823_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180722_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180901_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180726_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180829_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180818_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180830_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180823_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180910_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180715_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180816_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180817_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180730_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180902_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180908_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180731_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180717_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180722_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180816_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180805_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180813_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180831_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180906_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180913_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180715_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180808_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180813_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180717_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180904_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180905_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180804_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180804_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180918_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180827_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180821_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180810_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180809_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180815_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180913_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180719_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180721_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180721_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180731_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180913_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180719_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180723_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180723_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180914_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180722_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180913_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180715_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180918_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180808_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180729_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180912_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180813_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180818_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180814_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180729_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180804_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180909_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180717_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180801_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180806_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180805_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180911_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180821_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180722_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180824_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180727_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180820_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180824_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180815_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180807_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180903_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180816_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180815_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180901_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180909_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180821_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180909_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180801_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180720_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180801_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180914_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180907_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180904_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180830_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180818_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180827_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180807_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180820_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180823_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180810_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180831_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180803_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180805_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180825_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180807_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180719_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180816_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180812_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180819_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180813_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180724_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180828_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180716_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180917_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180824_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180829_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180822_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180827_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180917_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180911_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180827_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180815_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180811_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180912_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180806_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180828_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180728_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180805_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180725_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180810_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180718_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180719_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180814_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180717_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180915_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180806_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180730_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180909_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180720_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180916_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180729_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180904_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180807_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180909_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180715_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180821_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180916_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180804_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180813_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180731_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180903_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180910_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180802_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180907_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180810_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180804_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180725_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180821_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180826_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180904_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180726_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180823_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180816_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180809_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180720_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180823_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180831_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180804_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180823_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180903_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180728_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180915_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180902_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180718_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180912_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180826_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180915_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180903_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180901_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180729_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180719_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180725_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180808_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180809_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180904_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180828_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180831_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180723_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180909_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180901_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180716_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180831_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180809_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180803_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180912_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180720_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180717_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180727_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180908_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180804_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180908_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180814_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180723_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180723_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180910_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180811_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180803_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180718_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180907_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180808_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180906_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180812_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180810_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180715_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180802_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180807_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180731_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180830_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180724_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180819_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180812_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180911_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180905_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180818_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180916_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180819_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180918_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180724_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180906_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180726_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180728_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180730_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180727_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180903_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180902_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180822_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180817_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180917_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180821_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180915_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180812_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180824_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180831_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180808_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180812_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180805_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180816_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180915_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180912_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180905_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180819_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180809_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180721_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180727_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180825_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180801_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180728_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180830_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180718_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180829_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180720_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180806_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180715_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180820_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180716_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180901_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180814_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180908_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180821_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180829_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180908_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180914_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180731_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180722_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180812_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180725_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180916_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180808_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180909_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180913_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180802_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180821_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180808_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180728_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180730_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180823_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180905_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180908_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180830_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180724_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180817_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180731_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180801_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180818_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180901_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180723_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180830_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180824_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180814_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180825_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180914_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180901_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180827_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180813_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180906_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180825_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180722_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180831_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180718_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180802_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180717_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180810_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180731_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180807_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180809_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180721_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180722_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180716_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180715_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180719_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180720_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180717_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180917_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180907_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180917_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180910_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180828_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180814_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180804_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180802_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180918_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180906_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180831_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180822_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180819_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180820_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180730_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180811_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180820_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180801_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180726_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180911_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180728_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180826_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180731_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180916_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180826_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180730_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180719_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180722_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180715_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180907_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180729_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180721_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180830_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180816_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180815_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180810_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180910_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180818_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180916_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180902_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180820_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180811_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180903_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180801_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180726_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180721_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180805_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180908_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180725_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180908_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180910_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180721_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180905_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180724_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180911_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180729_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180719_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180801_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180912_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180806_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180918_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180901_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180918_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180811_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180811_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180802_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180820_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180730_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180809_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180807_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180722_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180728_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180802_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180914_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180914_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180912_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180824_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180810_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180915_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180917_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180807_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180916_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180822_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180912_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180903_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180816_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180806_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180801_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180818_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180913_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180720_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180806_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180902_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180906_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180718_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180722_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180724_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180825_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180918_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180803_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180906_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180719_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180730_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180917_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180819_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180807_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180802_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180720_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180715_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180915_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180803_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180830_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180826_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180911_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180914_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180906_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180825_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180729_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180805_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180817_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180826_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180908_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180828_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180721_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180912_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180731_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180826_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180910_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180727_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180718_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180812_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180911_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180727_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180826_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180917_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180904_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180917_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180901_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180911_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180808_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180826_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180915_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180913_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180723_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180809_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180902_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180823_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180820_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180911_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180910_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180723_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180719_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180830_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180806_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180815_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180829_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180812_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180813_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180827_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180905_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180801_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180822_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180815_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180726_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180729_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180811_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180803_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180822_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180915_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180821_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180913_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180812_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180914_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180911_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180816_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180724_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180717_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180723_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180725_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180903_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180913_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180909_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180827_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180720_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180821_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180815_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180807_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180805_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180914_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180819_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180913_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180811_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180716_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180716_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180901_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180907_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180728_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180823_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180819_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180902_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180917_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180819_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180727_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180902_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180831_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180725_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180725_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180904_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180724_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180718_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180918_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180724_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180823_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180724_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180822_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180824_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180827_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180910_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180811_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180828_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180718_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180828_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180720_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180817_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180825_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180726_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180820_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180906_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180816_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180824_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180905_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180910_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180903_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180825_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180728_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180908_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180730_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180818_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180909_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180828_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180716_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180804_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180725_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180902_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180822_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180730_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180727_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180814_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180829_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180817_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180818_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180813_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180805_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180726_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180803_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180907_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180729_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180915_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180822_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180808_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180725_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180808_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180916_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180829_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180912_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180716_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180815_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180723_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180918_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180905_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180803_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180918_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180814_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180902_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180819_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180804_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180916_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180904_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180721_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180805_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180813_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180905_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180802_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180802_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180810_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180727_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180811_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180717_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180820_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180729_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180909_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180717_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180829_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180810_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180907_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180814_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180903_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_7_20180806_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180812_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180907_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180828_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180727_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_2_20180904_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180809_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180827_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180827_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180817_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180803_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180716_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180813_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180726_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_3_20180817_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180716_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_9_20180728_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_5_20180806_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_1_20180907_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_6_20180731_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180809_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_0_20180817_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_8_20180814_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180904_000000000000.csv.parquet',\n",
       " 'Skip_Data/log_4_20180818_000000000000.csv.parquet']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_generate(batch_size=batch_size, shuffle=True):\n",
    "    while 1:\n",
    "        c = [ i for i in range(len(train_files))]\n",
    "        if shuffle:\n",
    "            random.shuffle(c)\n",
    "        j = 0\n",
    "        X_train_i = []\n",
    "        Y_train_i = []\n",
    "        \n",
    "        for i in c:\n",
    "            #print(train_files[i])\n",
    "            \n",
    "            tmp_data = pd.read_parquet(train_files[i])\n",
    "            input_data_i, output_data_i, input_data_context_id_i, input_data_start_id_i, input_data_end_id_i, \\\n",
    "            input_data_id_i, output_data_id_i, output_data_target_i = ProcessSessionCate(tmp_data,if_gen = 1, batch_size = batch_size, sample = 1)      \n",
    "            \n",
    "            n_round = int(input_data_i.shape[0]/batch_size)            \n",
    "            \n",
    "            for j in range(n_round):           \n",
    "                X_train_i = {\n",
    "                           'context': input_data_context_id_i[j * batch_size:(j + 1) * batch_size],\n",
    "                            'start': input_data_start_id_i[j * batch_size:(j + 1) * batch_size],\n",
    "                            'end': input_data_end_id_i[j * batch_size:(j + 1) * batch_size],\n",
    "                            'input_fea': input_data_i[j * batch_size:(j + 1) * batch_size],\n",
    "                             'output_fea': output_data_i[j * batch_size:(j + 1) * batch_size],\n",
    "                            'input_id': input_data_id_i[j * batch_size:(j + 1) * batch_size],\n",
    "                            'output_id': output_data_id_i[j * batch_size:(j + 1) * batch_size],\n",
    "                        }                \n",
    "                \n",
    "                Y_train_i = output_data_target_i[j * batch_size:(j + 1) * batch_size]\n",
    "                \n",
    "                yield (X_train_i,Y_train_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the validation set.\n",
    "\n",
    "count = 0\n",
    "for file in valid_files:\n",
    "    tmp_data = pd.read_parquet(file)\n",
    "    input_data_i, output_data_i, input_data_context_id_i, input_data_start_id_i, input_data_end_id_i, \\\n",
    "    input_data_id_i, output_data_id_i, output_data_target_i = ProcessSessionCate(tmp_data)\n",
    "\n",
    "    if count == 0:\n",
    "        valid_input = input_data_i\n",
    "        valid_output = output_data_i\n",
    "        valid_input_id = input_data_id_i\n",
    "        valid_input_data_context_id = input_data_context_id_i\n",
    "        valid_input_data_start_id = input_data_start_id_i\n",
    "        valid_input_data_end_id = input_data_end_id_i\n",
    "        valid_output_id = output_data_id_i\n",
    "        valid_target = output_data_target_i\n",
    "    else:\n",
    "        valid_input = np.concatenate((valid_input,input_data_i),axis=0)\n",
    "        valid_output = np.concatenate((valid_output,output_data_i),axis=0)\n",
    "        valid_input_data_context_id = np.concatenate((valid_input_data_context_id,input_data_context_id_i),axis=0)\n",
    "        valid_input_data_start_id = np.concatenate((valid_input_data_start_id,input_data_start_id_i),axis=0)\n",
    "        valid_input_data_end_id = np.concatenate((valid_input_data_end_id,input_data_end_id_i),axis=0)\n",
    "        valid_input_id = np.concatenate((valid_input_id,input_data_id_i),axis=0)\n",
    "        valid_output_id = np.concatenate((valid_output_id,output_data_id_i),axis=0)\n",
    "        valid_target = np.concatenate((valid_target,output_data_target_i),axis=0)\n",
    "\n",
    "    count  = count + 1\n",
    "    \n",
    "input_fea_dim = valid_input.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the validation set (cont.)\n",
    "\n",
    "X_valid = {\n",
    "   'context': valid_input_data_context_id,\n",
    "    'start': valid_input_data_start_id,\n",
    "    'end': valid_input_data_end_id,\n",
    "    'input_fea': valid_input,\n",
    "     'output_fea': valid_output,\n",
    "    'input_id': valid_input_id,\n",
    "    'output_id': valid_output_id,\n",
    "}\n",
    "\n",
    "Y_valid = valid_target\n",
    "\n",
    "#hkl.dump(Y_valid, data_path+'Y_valid.hkl', mode='w', compression='gzip')\n",
    "\n",
    "#hkl.dump(valid_output, data_path+'valid_output.hkl', mode='w', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def skip_model_5_mtsk_att(cell_size = 20):\n",
    "\n",
    "    input_data_context_id = Input(shape=[10], name=\"context\")\n",
    "    input_data_start_id = Input(shape=[10], name=\"start\")\n",
    "    input_data_end_id = Input(shape=[10], name=\"end\")\n",
    "    input_data = Input(shape=[10,input_fea_dim], name=\"input_fea\")\n",
    "    output_data_i = Input(shape=[10], name=\"output_fea\")\n",
    "    input_id = Input(shape=[10], name=\"input_id\")\n",
    "    output_id = Input(shape=[10], name=\"output_id\")\n",
    "\n",
    "    song_emb_layer = Embedding(\n",
    "        input_dim=spotify_song_array.shape[0],\n",
    "        output_dim=spotify_song_array.shape[1],\n",
    "        weights=[spotify_song_array],\n",
    "        trainable=False\n",
    "    )\n",
    "\n",
    "    context_emb_layer = Embedding(n_context_type,20)\n",
    "    reason_start_emb_layer = Embedding(n_reason_start,20)\n",
    "    reason_end_emb_layer = Embedding(n_reason_end,20)\n",
    "\n",
    "    emb_input_id = song_emb_layer(input_id)\n",
    "    emb_output_id = song_emb_layer(output_id)\n",
    "    emb_input_data_context_id = context_emb_layer(input_data_context_id)\n",
    "    emb_input_data_start_id = reason_start_emb_layer(input_data_start_id)\n",
    "    emb_input_data_end_id = reason_end_emb_layer(input_data_end_id)\n",
    "\n",
    "    input_data_a = concatenate([input_data,emb_input_id,emb_input_data_context_id,\n",
    "                              emb_input_data_start_id,emb_input_data_end_id])\n",
    "\n",
    "    # rnn layers\n",
    "#    encoder_outputs, state_h\n",
    "    \n",
    "    encoder_outputs, rnn_layer = GRU(cell_size, return_sequences=True, return_state=True) (input_data_a)\n",
    "    \n",
    "    rnn_layer_last = Lambda(slice_last)(input_data_a)      \n",
    "#    print(encoder_outputs.shape)\n",
    "    print(rnn_layer.shape)\n",
    "#    print(rnn_layer.shape)\n",
    "\n",
    "    \n",
    "    rnn_layer = concatenate([rnn_layer, rnn_layer_last])\n",
    "    \n",
    "    print(rnn_layer.shape)\n",
    "    \n",
    "    # output_data = Reshape([10,1])(output_data_i)\n",
    "    \n",
    "    output_data = concatenate([output_data_i, emb_output_id])\n",
    "\n",
    "    output_data = Dense(spotify_song_array.shape[1]+input_fea_dim+cell_size+60, activation='relu')(output_data)\n",
    "\n",
    "    rnn_layer_multi = Multiply()([output_data, rnn_layer])\n",
    "    \n",
    "    rnn_layer_reshape = Reshape([1,spotify_song_array.shape[1]+input_fea_dim+cell_size+60])(rnn_layer)\n",
    "    \n",
    "    rnn_layer_reshape = Lambda(tile_tile)(rnn_layer_reshape)\n",
    "\n",
    "    output_result = concatenate([rnn_layer_reshape, rnn_layer_multi, output_data])\n",
    "    \n",
    "    output_rnn_layer = Bidirectional(GRU(cell_size, return_sequences=True))(output_result)\n",
    "    \n",
    "    output_result = concatenate([output_result, output_rnn_layer])\n",
    "\n",
    "    output_result = Dense(1024, activation='elu')(output_result)\n",
    "    output_result_1 = Dense(784, activation='elu')(output_result)\n",
    "    #output_result_2 = Dense(784, activation='elu')(output_result_1)\n",
    "    \n",
    "    #output_result = concatenate([output_result, output_result_1, output_result_2])\n",
    "    \n",
    "    output_result = Dropout(0.2)(output_result_1)\n",
    "\n",
    "    output_result = Dense(8, activation='sigmoid')(output_result)\n",
    "    \n",
    "    #output_result = Reshape([10])(output_result)\n",
    "\n",
    "\n",
    "    model = Model(inputs=[input_data_context_id, input_data_start_id,\n",
    "                          input_data_end_id, input_data, output_data_i, input_id, output_id], outputs=output_result)\n",
    "\n",
    "    sgd = Adam(lr=0.0005)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['binary_crossentropy', 'binary_accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "checkpoint = ModelCheckpoint('Data/skip_net_glove_max_mtsk_lgb_best.hdf5', monitor='val_binary_accuracy', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = skip_model_5_mtsk_att()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_id (InputLayer)           (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "context (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "start (InputLayer)              (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "end (InputLayer)                (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_fea (InputLayer)          (None, 10, 14)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 10, 179)      663443631   input_id[0][0]                   \n",
      "                                                                 output_id[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 10, 25)       175         context[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 10, 25)       325         start[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 10, 25)       300         end[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10, 268)      0           input_fea[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "                                                                 embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     [(None, 10, 350), (N 649950      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_fea (InputLayer)         (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "output_id (InputLayer)          (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     [(None, 10, 350), (N 736050      gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 1)        0           output_fea[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 700)          0           gru_1[0][1]                      \n",
      "                                                                 gru_2[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 10, 180)      0           reshape_1[0][0]                  \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 1, 700)       0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10, 700)      126700      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 10, 700)      0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 10, 700)      0           dense_1[0][0]                    \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 10, 2100)     0           lambda_1[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 10, 700)      5147100     concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 10, 700)      2207100     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 10, 400)      1081200     bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 10, 400)      721200      bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 10, 4300)     0           concatenate_4[0][0]              \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10, 1000)     4301000     concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10, 784)      784784      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 10, 784)      0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10, 11)       8635        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 679,208,150\n",
      "Trainable params: 15,764,519\n",
      "Non-trainable params: 663,443,631\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:188: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., epochs=300, max_queue_size=35, validation_data=({'context..., callbacks=[<__main__..., steps_per_epoch=3000, verbose=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3000/3000 [==============================] - 1735s 578ms/step - loss: 0.2789 - binary_crossentropy: 0.2789 - binary_accuracy: 0.8734 - val_loss: 0.2821 - val_binary_crossentropy: 0.2821 - val_binary_accuracy: 0.8721\n",
      "0.7508228055989036\n",
      "\n",
      "Epoch 00001: val_binary_accuracy improved from -inf to 0.87209, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 2/300\n",
      "3000/3000 [==============================] - 1740s 580ms/step - loss: 0.2633 - binary_crossentropy: 0.2633 - binary_accuracy: 0.8809 - val_loss: 0.2773 - val_binary_crossentropy: 0.2773 - val_binary_accuracy: 0.8743\n",
      "0.7556039821812296\n",
      "\n",
      "Epoch 00002: val_binary_accuracy improved from 0.87209 to 0.87428, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 3/300\n",
      "3000/3000 [==============================] - 1837s 612ms/step - loss: 0.2598 - binary_crossentropy: 0.2598 - binary_accuracy: 0.8826 - val_loss: 0.2745 - val_binary_crossentropy: 0.2745 - val_binary_accuracy: 0.8757\n",
      "0.7587804405093413\n",
      "\n",
      "Epoch 00003: val_binary_accuracy improved from 0.87428 to 0.87570, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 4/300\n",
      "3000/3000 [==============================] - 1785s 595ms/step - loss: 0.2580 - binary_crossentropy: 0.2580 - binary_accuracy: 0.8834 - val_loss: 0.2742 - val_binary_crossentropy: 0.2742 - val_binary_accuracy: 0.8758\n",
      "0.7588114399988392\n",
      "\n",
      "Epoch 00004: val_binary_accuracy improved from 0.87570 to 0.87576, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 5/300\n",
      "3000/3000 [==============================] - 1745s 582ms/step - loss: 0.2563 - binary_crossentropy: 0.2563 - binary_accuracy: 0.8843 - val_loss: 0.2723 - val_binary_crossentropy: 0.2723 - val_binary_accuracy: 0.8766\n",
      "0.7601582688829762\n",
      "\n",
      "Epoch 00005: val_binary_accuracy improved from 0.87576 to 0.87655, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 6/300\n",
      "3000/3000 [==============================] - 1769s 590ms/step - loss: 0.2560 - binary_crossentropy: 0.2560 - binary_accuracy: 0.8844 - val_loss: 0.2726 - val_binary_crossentropy: 0.2726 - val_binary_accuracy: 0.8764\n",
      "0.7599221451119081\n",
      "\n",
      "Epoch 00006: val_binary_accuracy did not improve from 0.87655\n",
      "Epoch 7/300\n",
      "3000/3000 [==============================] - 1831s 610ms/step - loss: 0.2554 - binary_crossentropy: 0.2554 - binary_accuracy: 0.8847 - val_loss: 0.2714 - val_binary_crossentropy: 0.2714 - val_binary_accuracy: 0.8770\n",
      "0.7614332053340228\n",
      "\n",
      "Epoch 00007: val_binary_accuracy improved from 0.87655 to 0.87704, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 8/300\n",
      "3000/3000 [==============================] - 1793s 598ms/step - loss: 0.2552 - binary_crossentropy: 0.2552 - binary_accuracy: 0.8847 - val_loss: 0.2714 - val_binary_crossentropy: 0.2714 - val_binary_accuracy: 0.8771\n",
      "0.7615321398749731\n",
      "\n",
      "Epoch 00008: val_binary_accuracy improved from 0.87704 to 0.87705, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 9/300\n",
      "3000/3000 [==============================] - 1832s 611ms/step - loss: 0.2545 - binary_crossentropy: 0.2545 - binary_accuracy: 0.8851 - val_loss: 0.2712 - val_binary_crossentropy: 0.2712 - val_binary_accuracy: 0.8772\n",
      "0.7614879491133486\n",
      "\n",
      "Epoch 00009: val_binary_accuracy improved from 0.87705 to 0.87720, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 10/300\n",
      "3000/3000 [==============================] - 1775s 592ms/step - loss: 0.2548 - binary_crossentropy: 0.2548 - binary_accuracy: 0.8849 - val_loss: 0.2710 - val_binary_crossentropy: 0.2710 - val_binary_accuracy: 0.8774\n",
      "0.76190347418534\n",
      "\n",
      "Epoch 00010: val_binary_accuracy improved from 0.87720 to 0.87738, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 11/300\n",
      "3000/3000 [==============================] - 1759s 586ms/step - loss: 0.2540 - binary_crossentropy: 0.2540 - binary_accuracy: 0.8854 - val_loss: 0.2698 - val_binary_crossentropy: 0.2698 - val_binary_accuracy: 0.8778\n",
      "0.762302510167173\n",
      "\n",
      "Epoch 00011: val_binary_accuracy improved from 0.87738 to 0.87775, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 12/300\n",
      "3000/3000 [==============================] - 1817s 606ms/step - loss: 0.2533 - binary_crossentropy: 0.2533 - binary_accuracy: 0.8858 - val_loss: 0.2701 - val_binary_crossentropy: 0.2701 - val_binary_accuracy: 0.8777\n",
      "0.7625228044116891\n",
      "\n",
      "Epoch 00012: val_binary_accuracy did not improve from 0.87775\n",
      "Epoch 13/300\n",
      "3000/3000 [==============================] - 1827s 609ms/step - loss: 0.2539 - binary_crossentropy: 0.2539 - binary_accuracy: 0.8853 - val_loss: 0.2700 - val_binary_crossentropy: 0.2700 - val_binary_accuracy: 0.8778\n",
      "0.7624654223779379\n",
      "\n",
      "Epoch 00013: val_binary_accuracy improved from 0.87775 to 0.87776, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 14/300\n",
      "3000/3000 [==============================] - 1804s 601ms/step - loss: 0.2536 - binary_crossentropy: 0.2536 - binary_accuracy: 0.8855 - val_loss: 0.2696 - val_binary_crossentropy: 0.2696 - val_binary_accuracy: 0.8780\n",
      "0.763110475584934\n",
      "\n",
      "Epoch 00014: val_binary_accuracy improved from 0.87776 to 0.87796, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 15/300\n",
      "3000/3000 [==============================] - 1790s 597ms/step - loss: 0.2533 - binary_crossentropy: 0.2533 - binary_accuracy: 0.8857 - val_loss: 0.2699 - val_binary_crossentropy: 0.2699 - val_binary_accuracy: 0.8778\n",
      "0.762117832357399\n",
      "\n",
      "Epoch 00015: val_binary_accuracy did not improve from 0.87796\n",
      "Epoch 16/300\n",
      "3000/3000 [==============================] - 1831s 610ms/step - loss: 0.2539 - binary_crossentropy: 0.2539 - binary_accuracy: 0.8853 - val_loss: 0.2692 - val_binary_crossentropy: 0.2692 - val_binary_accuracy: 0.8781\n",
      "0.7635893187631335\n",
      "\n",
      "Epoch 00016: val_binary_accuracy improved from 0.87796 to 0.87813, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 17/300\n",
      "3000/3000 [==============================] - 1860s 620ms/step - loss: 0.2534 - binary_crossentropy: 0.2534 - binary_accuracy: 0.8856 - val_loss: 0.2698 - val_binary_crossentropy: 0.2698 - val_binary_accuracy: 0.8778\n",
      "0.7626454832424675\n",
      "\n",
      "Epoch 00017: val_binary_accuracy did not improve from 0.87813\n",
      "Epoch 18/300\n",
      "3000/3000 [==============================] - 1846s 615ms/step - loss: 0.2527 - binary_crossentropy: 0.2527 - binary_accuracy: 0.8860 - val_loss: 0.2688 - val_binary_crossentropy: 0.2688 - val_binary_accuracy: 0.8783\n",
      "0.763810272571256\n",
      "\n",
      "Epoch 00018: val_binary_accuracy improved from 0.87813 to 0.87834, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 19/300\n",
      "3000/3000 [==============================] - 1872s 624ms/step - loss: 0.2533 - binary_crossentropy: 0.2533 - binary_accuracy: 0.8857 - val_loss: 0.2694 - val_binary_crossentropy: 0.2694 - val_binary_accuracy: 0.8781\n",
      "0.7634494912785904\n",
      "\n",
      "Epoch 00019: val_binary_accuracy did not improve from 0.87834\n",
      "Epoch 20/300\n",
      "3000/3000 [==============================] - 1800s 600ms/step - loss: 0.2532 - binary_crossentropy: 0.2532 - binary_accuracy: 0.8857 - val_loss: 0.2691 - val_binary_crossentropy: 0.2691 - val_binary_accuracy: 0.8782\n",
      "0.7635372132382331\n",
      "\n",
      "Epoch 00020: val_binary_accuracy did not improve from 0.87834\n",
      "Epoch 21/300\n",
      "3000/3000 [==============================] - 1807s 602ms/step - loss: 0.2534 - binary_crossentropy: 0.2534 - binary_accuracy: 0.8855 - val_loss: 0.2692 - val_binary_crossentropy: 0.2692 - val_binary_accuracy: 0.8782\n",
      "0.7637304653748893\n",
      "\n",
      "Epoch 00021: val_binary_accuracy did not improve from 0.87834\n",
      "Epoch 22/300\n",
      "3000/3000 [==============================] - 1823s 608ms/step - loss: 0.2531 - binary_crossentropy: 0.2531 - binary_accuracy: 0.8857 - val_loss: 0.2691 - val_binary_crossentropy: 0.2691 - val_binary_accuracy: 0.8782\n",
      "0.7636796789772016\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0006399999838322401.\n",
      "\n",
      "Epoch 00022: val_binary_accuracy did not improve from 0.87834\n",
      "Epoch 23/300\n",
      "3000/3000 [==============================] - 1803s 601ms/step - loss: 0.2523 - binary_crossentropy: 0.2523 - binary_accuracy: 0.8861 - val_loss: 0.2690 - val_binary_crossentropy: 0.2690 - val_binary_accuracy: 0.8783\n",
      "0.7636447221060657\n",
      "\n",
      "Epoch 00023: val_binary_accuracy did not improve from 0.87834\n",
      "Epoch 24/300\n",
      "3000/3000 [==============================] - 1815s 605ms/step - loss: 0.2520 - binary_crossentropy: 0.2520 - binary_accuracy: 0.8863 - val_loss: 0.2682 - val_binary_crossentropy: 0.2682 - val_binary_accuracy: 0.8787\n",
      "0.7643524338556638\n",
      "\n",
      "Epoch 00024: val_binary_accuracy improved from 0.87834 to 0.87865, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 25/300\n",
      "3000/3000 [==============================] - 1822s 607ms/step - loss: 0.2517 - binary_crossentropy: 0.2517 - binary_accuracy: 0.8866 - val_loss: 0.2678 - val_binary_crossentropy: 0.2678 - val_binary_accuracy: 0.8787\n",
      "0.764826660088619\n",
      "\n",
      "Epoch 00025: val_binary_accuracy improved from 0.87865 to 0.87875, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 26/300\n",
      "3000/3000 [==============================] - 1824s 608ms/step - loss: 0.2518 - binary_crossentropy: 0.2518 - binary_accuracy: 0.8864 - val_loss: 0.2680 - val_binary_crossentropy: 0.2680 - val_binary_accuracy: 0.8787\n",
      "0.7646987047489899\n",
      "\n",
      "Epoch 00026: val_binary_accuracy did not improve from 0.87875\n",
      "Epoch 27/300\n",
      "3000/3000 [==============================] - 1831s 610ms/step - loss: 0.2519 - binary_crossentropy: 0.2519 - binary_accuracy: 0.8863 - val_loss: 0.2675 - val_binary_crossentropy: 0.2675 - val_binary_accuracy: 0.8790\n",
      "0.7652890141766602\n",
      "\n",
      "Epoch 00027: val_binary_accuracy improved from 0.87875 to 0.87897, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 28/300\n",
      "3000/3000 [==============================] - 1842s 614ms/step - loss: 0.2520 - binary_crossentropy: 0.2520 - binary_accuracy: 0.8862 - val_loss: 0.2677 - val_binary_crossentropy: 0.2677 - val_binary_accuracy: 0.8788\n",
      "0.7645859193723065\n",
      "\n",
      "Epoch 00028: val_binary_accuracy did not improve from 0.87897\n",
      "Epoch 29/300\n",
      "3000/3000 [==============================] - 1780s 593ms/step - loss: 0.2512 - binary_crossentropy: 0.2512 - binary_accuracy: 0.8867 - val_loss: 0.2676 - val_binary_crossentropy: 0.2676 - val_binary_accuracy: 0.8789\n",
      "0.764942743283334\n",
      "\n",
      "Epoch 00029: val_binary_accuracy did not improve from 0.87897\n",
      "Epoch 30/300\n",
      "3000/3000 [==============================] - 1809s 603ms/step - loss: 0.2515 - binary_crossentropy: 0.2515 - binary_accuracy: 0.8866 - val_loss: 0.2678 - val_binary_crossentropy: 0.2678 - val_binary_accuracy: 0.8789\n",
      "0.7651999730898048\n",
      "\n",
      "Epoch 00030: val_binary_accuracy did not improve from 0.87897\n",
      "Epoch 31/300\n",
      "3000/3000 [==============================] - 1802s 601ms/step - loss: 0.2516 - binary_crossentropy: 0.2516 - binary_accuracy: 0.8865 - val_loss: 0.2678 - val_binary_crossentropy: 0.2678 - val_binary_accuracy: 0.8789\n",
      "0.7651221445842573\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005119999870657921.\n",
      "\n",
      "Epoch 00031: val_binary_accuracy did not improve from 0.87897\n",
      "Epoch 32/300\n",
      "3000/3000 [==============================] - 1801s 600ms/step - loss: 0.2511 - binary_crossentropy: 0.2511 - binary_accuracy: 0.8867 - val_loss: 0.2665 - val_binary_crossentropy: 0.2665 - val_binary_accuracy: 0.8794\n",
      "0.766025746724937\n",
      "\n",
      "Epoch 00032: val_binary_accuracy improved from 0.87897 to 0.87937, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 33/300\n",
      "3000/3000 [==============================] - 1772s 591ms/step - loss: 0.2510 - binary_crossentropy: 0.2510 - binary_accuracy: 0.8868 - val_loss: 0.2666 - val_binary_crossentropy: 0.2666 - val_binary_accuracy: 0.8793\n",
      "0.7657896229538688\n",
      "\n",
      "Epoch 00033: val_binary_accuracy did not improve from 0.87937\n",
      "Epoch 34/300\n",
      "3000/3000 [==============================] - 1883s 628ms/step - loss: 0.2504 - binary_crossentropy: 0.2504 - binary_accuracy: 0.8871 - val_loss: 0.2669 - val_binary_crossentropy: 0.2669 - val_binary_accuracy: 0.8792\n",
      "0.7656102216529456\n",
      "\n",
      "Epoch 00034: val_binary_accuracy did not improve from 0.87937\n",
      "Epoch 35/300\n",
      "3000/3000 [==============================] - 1889s 630ms/step - loss: 0.2504 - binary_crossentropy: 0.2504 - binary_accuracy: 0.8871 - val_loss: 0.2665 - val_binary_crossentropy: 0.2665 - val_binary_accuracy: 0.8794\n",
      "0.7662763808953444\n",
      "\n",
      "Epoch 00035: val_binary_accuracy improved from 0.87937 to 0.87944, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 36/300\n",
      "3000/3000 [==============================] - 1840s 613ms/step - loss: 0.2510 - binary_crossentropy: 0.2510 - binary_accuracy: 0.8867 - val_loss: 0.2662 - val_binary_crossentropy: 0.2662 - val_binary_accuracy: 0.8795\n",
      "0.7664129105618559\n",
      "\n",
      "Epoch 00036: val_binary_accuracy improved from 0.87944 to 0.87952, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 37/300\n",
      "3000/3000 [==============================] - 1840s 613ms/step - loss: 0.2506 - binary_crossentropy: 0.2506 - binary_accuracy: 0.8870 - val_loss: 0.2675 - val_binary_crossentropy: 0.2675 - val_binary_accuracy: 0.8788\n",
      "0.76471849165718\n",
      "\n",
      "Epoch 00037: val_binary_accuracy did not improve from 0.87952\n",
      "Epoch 38/300\n",
      "3000/3000 [==============================] - 1819s 606ms/step - loss: 0.2505 - binary_crossentropy: 0.2505 - binary_accuracy: 0.8870 - val_loss: 0.2662 - val_binary_crossentropy: 0.2662 - val_binary_accuracy: 0.8796\n",
      "0.766336401183521\n",
      "\n",
      "Epoch 00038: val_binary_accuracy improved from 0.87952 to 0.87957, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 39/300\n",
      "3000/3000 [==============================] - 1825s 608ms/step - loss: 0.2504 - binary_crossentropy: 0.2504 - binary_accuracy: 0.8871 - val_loss: 0.2668 - val_binary_crossentropy: 0.2668 - val_binary_accuracy: 0.8793\n",
      "0.7659657264367604\n",
      "\n",
      "Epoch 00039: val_binary_accuracy did not improve from 0.87957\n",
      "Epoch 40/300\n",
      "3000/3000 [==============================] - 1785s 595ms/step - loss: 0.2505 - binary_crossentropy: 0.2505 - binary_accuracy: 0.8870 - val_loss: 0.2660 - val_binary_crossentropy: 0.2660 - val_binary_accuracy: 0.8797\n",
      "0.7666371621880099\n",
      "\n",
      "Epoch 00040: val_binary_accuracy improved from 0.87957 to 0.87966, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 41/300\n",
      "3000/3000 [==============================] - 1828s 609ms/step - loss: 0.2506 - binary_crossentropy: 0.2506 - binary_accuracy: 0.8870 - val_loss: 0.2667 - val_binary_crossentropy: 0.2667 - val_binary_accuracy: 0.8794\n",
      "0.7661306173383443\n",
      "\n",
      "Epoch 00041: val_binary_accuracy did not improve from 0.87966\n",
      "Epoch 42/300\n",
      "3000/3000 [==============================] - 1829s 610ms/step - loss: 0.2500 - binary_crossentropy: 0.2500 - binary_accuracy: 0.8873 - val_loss: 0.2662 - val_binary_crossentropy: 0.2662 - val_binary_accuracy: 0.8796\n",
      "0.7665309724473899\n",
      "\n",
      "Epoch 00042: val_binary_accuracy did not improve from 0.87966\n",
      "Epoch 43/300\n",
      "3000/3000 [==============================] - 1790s 597ms/step - loss: 0.2505 - binary_crossentropy: 0.2505 - binary_accuracy: 0.8870 - val_loss: 0.2667 - val_binary_crossentropy: 0.2667 - val_binary_accuracy: 0.8794\n",
      "0.7662744022045254\n",
      "\n",
      "Epoch 00043: val_binary_accuracy did not improve from 0.87966\n",
      "Epoch 44/300\n",
      "3000/3000 [==============================] - 1831s 610ms/step - loss: 0.2506 - binary_crossentropy: 0.2506 - binary_accuracy: 0.8869 - val_loss: 0.2661 - val_binary_crossentropy: 0.2661 - val_binary_accuracy: 0.8796\n",
      "0.7668053509076255\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.00040959999896585943.\n",
      "\n",
      "Epoch 00044: val_binary_accuracy did not improve from 0.87966\n",
      "Epoch 45/300\n",
      "3000/3000 [==============================] - 1863s 621ms/step - loss: 0.2493 - binary_crossentropy: 0.2493 - binary_accuracy: 0.8877 - val_loss: 0.2659 - val_binary_crossentropy: 0.2659 - val_binary_accuracy: 0.8796\n",
      "0.7665751632090144\n",
      "\n",
      "Epoch 00045: val_binary_accuracy did not improve from 0.87966\n",
      "Epoch 46/300\n",
      "3000/3000 [==============================] - 1871s 624ms/step - loss: 0.2500 - binary_crossentropy: 0.2500 - binary_accuracy: 0.8872 - val_loss: 0.2655 - val_binary_crossentropy: 0.2655 - val_binary_accuracy: 0.8799\n",
      "0.7672057060166712\n",
      "\n",
      "Epoch 00046: val_binary_accuracy improved from 0.87966 to 0.87988, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 47/300\n",
      "3000/3000 [==============================] - 1807s 602ms/step - loss: 0.2497 - binary_crossentropy: 0.2497 - binary_accuracy: 0.8874 - val_loss: 0.2657 - val_binary_crossentropy: 0.2657 - val_binary_accuracy: 0.8798\n",
      "0.7668640520685893\n",
      "\n",
      "Epoch 00047: val_binary_accuracy did not improve from 0.87988\n",
      "Epoch 48/300\n",
      "3000/3000 [==============================] - 1876s 625ms/step - loss: 0.2490 - binary_crossentropy: 0.2490 - binary_accuracy: 0.8878 - val_loss: 0.2659 - val_binary_crossentropy: 0.2659 - val_binary_accuracy: 0.8797\n",
      "0.7670441129331189\n",
      "\n",
      "Epoch 00048: val_binary_accuracy did not improve from 0.87988\n",
      "Epoch 49/300\n",
      "3000/3000 [==============================] - 1836s 612ms/step - loss: 0.2488 - binary_crossentropy: 0.2488 - binary_accuracy: 0.8879 - val_loss: 0.2651 - val_binary_crossentropy: 0.2651 - val_binary_accuracy: 0.8801\n",
      "0.7675381260742642\n",
      "\n",
      "Epoch 00049: val_binary_accuracy improved from 0.87988 to 0.88006, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 50/300\n",
      "3000/3000 [==============================] - 1757s 586ms/step - loss: 0.2495 - binary_crossentropy: 0.2495 - binary_accuracy: 0.8875 - val_loss: 0.2653 - val_binary_crossentropy: 0.2653 - val_binary_accuracy: 0.8800\n",
      "0.7672512159055083\n",
      "\n",
      "Epoch 00050: val_binary_accuracy did not improve from 0.88006\n",
      "Epoch 51/300\n",
      "3000/3000 [==============================] - 1825s 608ms/step - loss: 0.2490 - binary_crossentropy: 0.2490 - binary_accuracy: 0.8878 - val_loss: 0.2657 - val_binary_crossentropy: 0.2657 - val_binary_accuracy: 0.8797\n",
      "0.7660996178488465\n",
      "\n",
      "Epoch 00051: val_binary_accuracy did not improve from 0.88006\n",
      "Epoch 52/300\n",
      "3000/3000 [==============================] - 1836s 612ms/step - loss: 0.2501 - binary_crossentropy: 0.2501 - binary_accuracy: 0.8871 - val_loss: 0.2649 - val_binary_crossentropy: 0.2649 - val_binary_accuracy: 0.8801\n",
      "0.7674959140034587\n",
      "\n",
      "Epoch 00052: val_binary_accuracy improved from 0.88006 to 0.88014, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 53/300\n",
      "3000/3000 [==============================] - 1858s 619ms/step - loss: 0.2500 - binary_crossentropy: 0.2500 - binary_accuracy: 0.8871 - val_loss: 0.2651 - val_binary_crossentropy: 0.2651 - val_binary_accuracy: 0.8801\n",
      "0.7674662336411736\n",
      "\n",
      "Epoch 00053: val_binary_accuracy did not improve from 0.88014\n",
      "Epoch 54/300\n",
      "3000/3000 [==============================] - 1830s 610ms/step - loss: 0.2490 - binary_crossentropy: 0.2490 - binary_accuracy: 0.8877 - val_loss: 0.2653 - val_binary_crossentropy: 0.2653 - val_binary_accuracy: 0.8799\n",
      "0.7672360459425626\n",
      "\n",
      "Epoch 00054: val_binary_accuracy did not improve from 0.88014\n",
      "Epoch 55/300\n",
      "3000/3000 [==============================] - 1814s 605ms/step - loss: 0.2495 - binary_crossentropy: 0.2495 - binary_accuracy: 0.8875 - val_loss: 0.2655 - val_binary_crossentropy: 0.2655 - val_binary_accuracy: 0.8799\n",
      "0.7668917537400555\n",
      "\n",
      "Epoch 00055: val_binary_accuracy did not improve from 0.88014\n",
      "Epoch 56/300\n",
      "3000/3000 [==============================] - 1800s 600ms/step - loss: 0.2491 - binary_crossentropy: 0.2491 - binary_accuracy: 0.8877 - val_loss: 0.2649 - val_binary_crossentropy: 0.2649 - val_binary_accuracy: 0.8800\n",
      "0.7673765329907121\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.00032768000382930044.\n",
      "\n",
      "Epoch 00056: val_binary_accuracy did not improve from 0.88014\n",
      "Epoch 57/300\n",
      "3000/3000 [==============================] - 1739s 580ms/step - loss: 0.2487 - binary_crossentropy: 0.2487 - binary_accuracy: 0.8879 - val_loss: 0.2649 - val_binary_crossentropy: 0.2649 - val_binary_accuracy: 0.8802\n",
      "0.7678243766794138\n",
      "\n",
      "Epoch 00057: val_binary_accuracy improved from 0.88014 to 0.88020, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 58/300\n",
      "3000/3000 [==============================] - 1861s 620ms/step - loss: 0.2487 - binary_crossentropy: 0.2487 - binary_accuracy: 0.8878 - val_loss: 0.2642 - val_binary_crossentropy: 0.2642 - val_binary_accuracy: 0.8804\n",
      "0.7681409672104549\n",
      "\n",
      "Epoch 00058: val_binary_accuracy improved from 0.88020 to 0.88041, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 59/300\n",
      "3000/3000 [==============================] - 1862s 621ms/step - loss: 0.2486 - binary_crossentropy: 0.2486 - binary_accuracy: 0.8879 - val_loss: 0.2645 - val_binary_crossentropy: 0.2645 - val_binary_accuracy: 0.8803\n",
      "0.7680717130317897\n",
      "\n",
      "Epoch 00059: val_binary_accuracy did not improve from 0.88041\n",
      "Epoch 60/300\n",
      "3000/3000 [==============================] - 1846s 615ms/step - loss: 0.2488 - binary_crossentropy: 0.2488 - binary_accuracy: 0.8878 - val_loss: 0.2649 - val_binary_crossentropy: 0.2649 - val_binary_accuracy: 0.8802\n",
      "0.7676265075975132\n",
      "\n",
      "Epoch 00060: val_binary_accuracy did not improve from 0.88041\n",
      "Epoch 61/300\n",
      "3000/3000 [==============================] - 1827s 609ms/step - loss: 0.2488 - binary_crossentropy: 0.2488 - binary_accuracy: 0.8878 - val_loss: 0.2647 - val_binary_crossentropy: 0.2647 - val_binary_accuracy: 0.8802\n",
      "0.7677834837358211\n",
      "\n",
      "Epoch 00061: val_binary_accuracy did not improve from 0.88041\n",
      "Epoch 62/300\n",
      "3000/3000 [==============================] - 1762s 587ms/step - loss: 0.2487 - binary_crossentropy: 0.2487 - binary_accuracy: 0.8879 - val_loss: 0.2643 - val_binary_crossentropy: 0.2643 - val_binary_accuracy: 0.8804\n",
      "0.7682570504051699\n",
      "\n",
      "Epoch 00062: val_binary_accuracy improved from 0.88041 to 0.88045, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 63/300\n",
      "3000/3000 [==============================] - 1814s 605ms/step - loss: 0.2482 - binary_crossentropy: 0.2482 - binary_accuracy: 0.8881 - val_loss: 0.2645 - val_binary_crossentropy: 0.2645 - val_binary_accuracy: 0.8804\n",
      "0.7680895212491607\n",
      "\n",
      "Epoch 00063: val_binary_accuracy did not improve from 0.88045\n",
      "Epoch 64/300\n",
      "3000/3000 [==============================] - 1787s 596ms/step - loss: 0.2487 - binary_crossentropy: 0.2487 - binary_accuracy: 0.8878 - val_loss: 0.2646 - val_binary_crossentropy: 0.2646 - val_binary_accuracy: 0.8803\n",
      "0.7677973345715541\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0002621439984068275.\n",
      "\n",
      "Epoch 00064: val_binary_accuracy did not improve from 0.88045\n",
      "Epoch 65/300\n",
      "3000/3000 [==============================] - 1841s 614ms/step - loss: 0.2485 - binary_crossentropy: 0.2485 - binary_accuracy: 0.8880 - val_loss: 0.2643 - val_binary_crossentropy: 0.2643 - val_binary_accuracy: 0.8805\n",
      "0.7685901300263693\n",
      "\n",
      "Epoch 00065: val_binary_accuracy improved from 0.88045 to 0.88046, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 66/300\n",
      "3000/3000 [==============================] - 1853s 618ms/step - loss: 0.2485 - binary_crossentropy: 0.2485 - binary_accuracy: 0.8879 - val_loss: 0.2635 - val_binary_crossentropy: 0.2635 - val_binary_accuracy: 0.8808\n",
      "0.7686824689312564\n",
      "\n",
      "Epoch 00066: val_binary_accuracy improved from 0.88046 to 0.88079, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 67/300\n",
      "3000/3000 [==============================] - 1816s 605ms/step - loss: 0.2478 - binary_crossentropy: 0.2478 - binary_accuracy: 0.8884 - val_loss: 0.2644 - val_binary_crossentropy: 0.2644 - val_binary_accuracy: 0.8804\n",
      "0.7679147368934818\n",
      "\n",
      "Epoch 00067: val_binary_accuracy did not improve from 0.88079\n",
      "Epoch 68/300\n",
      "3000/3000 [==============================] - 1815s 605ms/step - loss: 0.2482 - binary_crossentropy: 0.2482 - binary_accuracy: 0.8881 - val_loss: 0.2640 - val_binary_crossentropy: 0.2640 - val_binary_accuracy: 0.8805\n",
      "0.768394899198894\n",
      "\n",
      "Epoch 00068: val_binary_accuracy did not improve from 0.88079\n",
      "Epoch 69/300\n",
      "3000/3000 [==============================] - 1790s 597ms/step - loss: 0.2486 - binary_crossentropy: 0.2486 - binary_accuracy: 0.8879 - val_loss: 0.2640 - val_binary_crossentropy: 0.2640 - val_binary_accuracy: 0.8806\n",
      "0.768483280722143\n",
      "\n",
      "Epoch 00069: val_binary_accuracy did not improve from 0.88079\n",
      "Epoch 70/300\n",
      "3000/3000 [==============================] - 1810s 603ms/step - loss: 0.2482 - binary_crossentropy: 0.2482 - binary_accuracy: 0.8881 - val_loss: 0.2641 - val_binary_crossentropy: 0.2641 - val_binary_accuracy: 0.8806\n",
      "0.7683421341103872\n",
      "\n",
      "Epoch 00070: val_binary_accuracy did not improve from 0.88079\n",
      "Epoch 71/300\n",
      "3000/3000 [==============================] - 1838s 613ms/step - loss: 0.2479 - binary_crossentropy: 0.2479 - binary_accuracy: 0.8883 - val_loss: 0.2641 - val_binary_crossentropy: 0.2641 - val_binary_accuracy: 0.8806\n",
      "0.768665979841098\n",
      "\n",
      "Epoch 00071: val_binary_accuracy did not improve from 0.88079\n",
      "Epoch 72/300\n",
      "3000/3000 [==============================] - 1878s 626ms/step - loss: 0.2481 - binary_crossentropy: 0.2481 - binary_accuracy: 0.8882 - val_loss: 0.2642 - val_binary_crossentropy: 0.2642 - val_binary_accuracy: 0.8805\n",
      "0.7681963705533871\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 0.0002097151940688491.\n",
      "\n",
      "Epoch 00072: val_binary_accuracy did not improve from 0.88079\n",
      "Epoch 73/300\n",
      "3000/3000 [==============================] - 1829s 610ms/step - loss: 0.2480 - binary_crossentropy: 0.2480 - binary_accuracy: 0.8882 - val_loss: 0.2637 - val_binary_crossentropy: 0.2637 - val_binary_accuracy: 0.8808\n",
      "0.7689898255718086\n",
      "\n",
      "Epoch 00073: val_binary_accuracy improved from 0.88079 to 0.88079, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 74/300\n",
      "3000/3000 [==============================] - 1886s 629ms/step - loss: 0.2478 - binary_crossentropy: 0.2478 - binary_accuracy: 0.8883 - val_loss: 0.2635 - val_binary_crossentropy: 0.2635 - val_binary_accuracy: 0.8809\n",
      "0.7692760761769583\n",
      "\n",
      "Epoch 00074: val_binary_accuracy improved from 0.88079 to 0.88085, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 75/300\n",
      "3000/3000 [==============================] - 1848s 616ms/step - loss: 0.2475 - binary_crossentropy: 0.2475 - binary_accuracy: 0.8885 - val_loss: 0.2636 - val_binary_crossentropy: 0.2636 - val_binary_accuracy: 0.8808\n",
      "0.7690768879678449\n",
      "\n",
      "Epoch 00075: val_binary_accuracy did not improve from 0.88085\n",
      "Epoch 76/300\n",
      "3000/3000 [==============================] - 1886s 629ms/step - loss: 0.2476 - binary_crossentropy: 0.2476 - binary_accuracy: 0.8884 - val_loss: 0.2632 - val_binary_crossentropy: 0.2632 - val_binary_accuracy: 0.8809\n",
      "0.7691072278937364\n",
      "\n",
      "Epoch 00076: val_binary_accuracy improved from 0.88085 to 0.88092, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 77/300\n",
      "3000/3000 [==============================] - 1828s 609ms/step - loss: 0.2473 - binary_crossentropy: 0.2473 - binary_accuracy: 0.8886 - val_loss: 0.2630 - val_binary_crossentropy: 0.2630 - val_binary_accuracy: 0.8810\n",
      "0.7692965226487547\n",
      "\n",
      "Epoch 00077: val_binary_accuracy improved from 0.88092 to 0.88100, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 78/300\n",
      "3000/3000 [==============================] - 1858s 619ms/step - loss: 0.2479 - binary_crossentropy: 0.2479 - binary_accuracy: 0.8882 - val_loss: 0.2636 - val_binary_crossentropy: 0.2636 - val_binary_accuracy: 0.8808\n",
      "0.7689364009196955\n",
      "\n",
      "Epoch 00078: val_binary_accuracy did not improve from 0.88100\n",
      "Epoch 79/300\n",
      "3000/3000 [==============================] - 1857s 619ms/step - loss: 0.2473 - binary_crossentropy: 0.2473 - binary_accuracy: 0.8886 - val_loss: 0.2636 - val_binary_crossentropy: 0.2636 - val_binary_accuracy: 0.8808\n",
      "0.7687530422371343\n",
      "\n",
      "Epoch 00079: val_binary_accuracy did not improve from 0.88100\n",
      "Epoch 80/300\n",
      "3000/3000 [==============================] - 1813s 604ms/step - loss: 0.2474 - binary_crossentropy: 0.2474 - binary_accuracy: 0.8884 - val_loss: 0.2631 - val_binary_crossentropy: 0.2631 - val_binary_accuracy: 0.8810\n",
      "0.7693473090464426\n",
      "\n",
      "Epoch 00080: val_binary_accuracy improved from 0.88100 to 0.88101, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 81/300\n",
      "3000/3000 [==============================] - 1841s 614ms/step - loss: 0.2473 - binary_crossentropy: 0.2473 - binary_accuracy: 0.8886 - val_loss: 0.2634 - val_binary_crossentropy: 0.2634 - val_binary_accuracy: 0.8809\n",
      "0.7692879483218723\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.0001677721505984664.\n",
      "\n",
      "Epoch 00081: val_binary_accuracy did not improve from 0.88101\n",
      "Epoch 82/300\n",
      "3000/3000 [==============================] - 1849s 616ms/step - loss: 0.2471 - binary_crossentropy: 0.2471 - binary_accuracy: 0.8887 - val_loss: 0.2630 - val_binary_crossentropy: 0.2630 - val_binary_accuracy: 0.8810\n",
      "0.769495710857868\n",
      "\n",
      "Epoch 00082: val_binary_accuracy improved from 0.88101 to 0.88101, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 83/300\n",
      "3000/3000 [==============================] - 1802s 601ms/step - loss: 0.2477 - binary_crossentropy: 0.2477 - binary_accuracy: 0.8883 - val_loss: 0.2632 - val_binary_crossentropy: 0.2632 - val_binary_accuracy: 0.8810\n",
      "0.7692351832333655\n",
      "\n",
      "Epoch 00083: val_binary_accuracy did not improve from 0.88101\n",
      "Epoch 84/300\n",
      "3000/3000 [==============================] - 1802s 601ms/step - loss: 0.2470 - binary_crossentropy: 0.2470 - binary_accuracy: 0.8887 - val_loss: 0.2633 - val_binary_crossentropy: 0.2633 - val_binary_accuracy: 0.8809\n",
      "0.7689654217183742\n",
      "\n",
      "Epoch 00084: val_binary_accuracy did not improve from 0.88101\n",
      "Epoch 85/300\n",
      "3000/3000 [==============================] - 1862s 621ms/step - loss: 0.2469 - binary_crossentropy: 0.2469 - binary_accuracy: 0.8887 - val_loss: 0.2629 - val_binary_crossentropy: 0.2629 - val_binary_accuracy: 0.8811\n",
      "0.7694792217677097\n",
      "\n",
      "Epoch 00085: val_binary_accuracy improved from 0.88101 to 0.88106, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 86/300\n",
      "3000/3000 [==============================] - 1848s 616ms/step - loss: 0.2473 - binary_crossentropy: 0.2473 - binary_accuracy: 0.8885 - val_loss: 0.2635 - val_binary_crossentropy: 0.2635 - val_binary_accuracy: 0.8809\n",
      "0.7691804394540396\n",
      "\n",
      "Epoch 00086: val_binary_accuracy did not improve from 0.88106\n",
      "Epoch 87/300\n",
      "3000/3000 [==============================] - 1866s 622ms/step - loss: 0.2475 - binary_crossentropy: 0.2475 - binary_accuracy: 0.8884 - val_loss: 0.2630 - val_binary_crossentropy: 0.2630 - val_binary_accuracy: 0.8810\n",
      "0.7694844982765603\n",
      "\n",
      "Epoch 00087: val_binary_accuracy did not improve from 0.88106\n",
      "Epoch 88/300\n",
      "3000/3000 [==============================] - 1831s 610ms/step - loss: 0.2475 - binary_crossentropy: 0.2475 - binary_accuracy: 0.8884 - val_loss: 0.2632 - val_binary_crossentropy: 0.2632 - val_binary_accuracy: 0.8810\n",
      "0.7694099675890443\n",
      "\n",
      "Epoch 00088: val_binary_accuracy did not improve from 0.88106\n",
      "Epoch 89/300\n",
      "3000/3000 [==============================] - 1788s 596ms/step - loss: 0.2471 - binary_crossentropy: 0.2471 - binary_accuracy: 0.8886 - val_loss: 0.2631 - val_binary_crossentropy: 0.2631 - val_binary_accuracy: 0.8810\n",
      "0.7692285875973022\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.00013421771582216026.\n",
      "\n",
      "Epoch 00089: val_binary_accuracy did not improve from 0.88106\n",
      "Epoch 90/300\n",
      "3000/3000 [==============================] - 1843s 614ms/step - loss: 0.2470 - binary_crossentropy: 0.2470 - binary_accuracy: 0.8887 - val_loss: 0.2628 - val_binary_crossentropy: 0.2628 - val_binary_accuracy: 0.8812\n",
      "0.7696025601620944\n",
      "\n",
      "Epoch 00090: val_binary_accuracy improved from 0.88106 to 0.88118, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 91/300\n",
      "3000/3000 [==============================] - 1824s 608ms/step - loss: 0.2468 - binary_crossentropy: 0.2468 - binary_accuracy: 0.8888 - val_loss: 0.2629 - val_binary_crossentropy: 0.2629 - val_binary_accuracy: 0.8811\n",
      "0.7694633922411576\n",
      "\n",
      "Epoch 00091: val_binary_accuracy did not improve from 0.88118\n",
      "Epoch 92/300\n",
      "3000/3000 [==============================] - 1811s 604ms/step - loss: 0.2472 - binary_crossentropy: 0.2472 - binary_accuracy: 0.8885 - val_loss: 0.2628 - val_binary_crossentropy: 0.2628 - val_binary_accuracy: 0.8812\n",
      "0.7696533465597822\n",
      "\n",
      "Epoch 00092: val_binary_accuracy improved from 0.88118 to 0.88119, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 93/300\n",
      "3000/3000 [==============================] - 1796s 599ms/step - loss: 0.2474 - binary_crossentropy: 0.2474 - binary_accuracy: 0.8884 - val_loss: 0.2630 - val_binary_crossentropy: 0.2630 - val_binary_accuracy: 0.8811\n",
      "0.7695300081653974\n",
      "\n",
      "Epoch 00093: val_binary_accuracy did not improve from 0.88119\n",
      "Epoch 94/300\n",
      "3000/3000 [==============================] - 1800s 600ms/step - loss: 0.2466 - binary_crossentropy: 0.2466 - binary_accuracy: 0.8889 - val_loss: 0.2627 - val_binary_crossentropy: 0.2627 - val_binary_accuracy: 0.8812\n",
      "0.7697681106272846\n",
      "\n",
      "Epoch 00094: val_binary_accuracy improved from 0.88119 to 0.88119, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 95/300\n",
      "3000/3000 [==============================] - 1845s 615ms/step - loss: 0.2464 - binary_crossentropy: 0.2464 - binary_accuracy: 0.8890 - val_loss: 0.2627 - val_binary_crossentropy: 0.2627 - val_binary_accuracy: 0.8812\n",
      "0.7695715606725966\n",
      "\n",
      "Epoch 00095: val_binary_accuracy did not improve from 0.88119\n",
      "Epoch 96/300\n",
      "3000/3000 [==============================] - 1834s 611ms/step - loss: 0.2463 - binary_crossentropy: 0.2463 - binary_accuracy: 0.8891 - val_loss: 0.2625 - val_binary_crossentropy: 0.2625 - val_binary_accuracy: 0.8813\n",
      "0.7697298559381172\n",
      "\n",
      "Epoch 00096: val_binary_accuracy improved from 0.88119 to 0.88126, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 97/300\n",
      "3000/3000 [==============================] - 1803s 601ms/step - loss: 0.2466 - binary_crossentropy: 0.2466 - binary_accuracy: 0.8889 - val_loss: 0.2631 - val_binary_crossentropy: 0.2631 - val_binary_accuracy: 0.8811\n",
      "0.7695352846742481\n",
      "\n",
      "Epoch 00097: val_binary_accuracy did not improve from 0.88126\n",
      "Epoch 98/300\n",
      "3000/3000 [==============================] - 1818s 606ms/step - loss: 0.2472 - binary_crossentropy: 0.2472 - binary_accuracy: 0.8885 - val_loss: 0.2627 - val_binary_crossentropy: 0.2627 - val_binary_accuracy: 0.8812\n",
      "0.7699415758557508\n",
      "\n",
      "Epoch 00098: val_binary_accuracy did not improve from 0.88126\n",
      "Epoch 99/300\n",
      "3000/3000 [==============================] - 1766s 589ms/step - loss: 0.2470 - binary_crossentropy: 0.2470 - binary_accuracy: 0.8886 - val_loss: 0.2627 - val_binary_crossentropy: 0.2627 - val_binary_accuracy: 0.8812\n",
      "0.7698657260410222\n",
      "\n",
      "Epoch 00099: val_binary_accuracy did not improve from 0.88126\n",
      "Epoch 100/300\n",
      "3000/3000 [==============================] - 1742s 581ms/step - loss: 0.2465 - binary_crossentropy: 0.2465 - binary_accuracy: 0.8890 - val_loss: 0.2626 - val_binary_crossentropy: 0.2626 - val_binary_accuracy: 0.8813\n",
      "0.7700246808701491\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 0.00010737417032942177.\n",
      "\n",
      "Epoch 00100: val_binary_accuracy improved from 0.88126 to 0.88132, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 101/300\n",
      "3000/3000 [==============================] - 1735s 578ms/step - loss: 0.2462 - binary_crossentropy: 0.2462 - binary_accuracy: 0.8891 - val_loss: 0.2627 - val_binary_crossentropy: 0.2627 - val_binary_accuracy: 0.8812\n",
      "0.7695933262716057\n",
      "\n",
      "Epoch 00101: val_binary_accuracy did not improve from 0.88132\n",
      "Epoch 102/300\n",
      "3000/3000 [==============================] - 1857s 619ms/step - loss: 0.2466 - binary_crossentropy: 0.2466 - binary_accuracy: 0.8888 - val_loss: 0.2624 - val_binary_crossentropy: 0.2624 - val_binary_accuracy: 0.8813\n",
      "0.7696889629945243\n",
      "\n",
      "Epoch 00102: val_binary_accuracy improved from 0.88132 to 0.88133, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 103/300\n",
      "3000/3000 [==============================] - 1825s 608ms/step - loss: 0.2465 - binary_crossentropy: 0.2465 - binary_accuracy: 0.8889 - val_loss: 0.2623 - val_binary_crossentropy: 0.2623 - val_binary_accuracy: 0.8814\n",
      "0.7700279786881807\n",
      "\n",
      "Epoch 00103: val_binary_accuracy improved from 0.88133 to 0.88136, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 104/300\n",
      "3000/3000 [==============================] - 1795s 598ms/step - loss: 0.2466 - binary_crossentropy: 0.2466 - binary_accuracy: 0.8889 - val_loss: 0.2624 - val_binary_crossentropy: 0.2624 - val_binary_accuracy: 0.8813\n",
      "0.7700444677783391\n",
      "\n",
      "Epoch 00104: val_binary_accuracy did not improve from 0.88136\n",
      "Epoch 105/300\n",
      "3000/3000 [==============================] - 1787s 596ms/step - loss: 0.2468 - binary_crossentropy: 0.2468 - binary_accuracy: 0.8888 - val_loss: 0.2623 - val_binary_crossentropy: 0.2623 - val_binary_accuracy: 0.8814\n",
      "0.7702693789680995\n",
      "\n",
      "Epoch 00105: val_binary_accuracy improved from 0.88136 to 0.88136, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 106/300\n",
      "3000/3000 [==============================] - 1856s 619ms/step - loss: 0.2464 - binary_crossentropy: 0.2464 - binary_accuracy: 0.8890 - val_loss: 0.2625 - val_binary_crossentropy: 0.2625 - val_binary_accuracy: 0.8814\n",
      "0.7700675525045609\n",
      "\n",
      "Epoch 00106: val_binary_accuracy improved from 0.88136 to 0.88137, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 107/300\n",
      "3000/3000 [==============================] - 1784s 595ms/step - loss: 0.2461 - binary_crossentropy: 0.2461 - binary_accuracy: 0.8892 - val_loss: 0.2623 - val_binary_crossentropy: 0.2623 - val_binary_accuracy: 0.8813\n",
      "0.7700200639249047\n",
      "\n",
      "Epoch 00107: val_binary_accuracy did not improve from 0.88137\n",
      "Epoch 108/300\n",
      "3000/3000 [==============================] - 1808s 603ms/step - loss: 0.2468 - binary_crossentropy: 0.2468 - binary_accuracy: 0.8888 - val_loss: 0.2626 - val_binary_crossentropy: 0.2626 - val_binary_accuracy: 0.8813\n",
      "0.7698327478607054\n",
      "\n",
      "Epoch 00108: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "\n",
      "Epoch 00108: val_binary_accuracy did not improve from 0.88137\n",
      "Epoch 109/300\n",
      "3000/3000 [==============================] - 1842s 614ms/step - loss: 0.2470 - binary_crossentropy: 0.2470 - binary_accuracy: 0.8886 - val_loss: 0.2624 - val_binary_crossentropy: 0.2624 - val_binary_accuracy: 0.8813\n",
      "0.770020723488511\n",
      "\n",
      "Epoch 00109: val_binary_accuracy did not improve from 0.88137\n",
      "Epoch 110/300\n",
      "3000/3000 [==============================] - 1800s 600ms/step - loss: 0.2466 - binary_crossentropy: 0.2466 - binary_accuracy: 0.8888 - val_loss: 0.2623 - val_binary_crossentropy: 0.2623 - val_binary_accuracy: 0.8814\n",
      "0.7703795260903575\n",
      "\n",
      "Epoch 00110: val_binary_accuracy improved from 0.88137 to 0.88141, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 111/300\n",
      "3000/3000 [==============================] - 1800s 600ms/step - loss: 0.2462 - binary_crossentropy: 0.2462 - binary_accuracy: 0.8891 - val_loss: 0.2624 - val_binary_crossentropy: 0.2624 - val_binary_accuracy: 0.8814\n",
      "0.7701631892274795\n",
      "\n",
      "Epoch 00111: val_binary_accuracy did not improve from 0.88141\n",
      "Epoch 112/300\n",
      "3000/3000 [==============================] - 1802s 601ms/step - loss: 0.2466 - binary_crossentropy: 0.2466 - binary_accuracy: 0.8889 - val_loss: 0.2622 - val_binary_crossentropy: 0.2622 - val_binary_accuracy: 0.8815\n",
      "0.7703762282723259\n",
      "\n",
      "Epoch 00112: val_binary_accuracy improved from 0.88141 to 0.88146, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 113/300\n",
      "3000/3000 [==============================] - 1828s 609ms/step - loss: 0.2460 - binary_crossentropy: 0.2460 - binary_accuracy: 0.8891 - val_loss: 0.2621 - val_binary_crossentropy: 0.2621 - val_binary_accuracy: 0.8815\n",
      "0.7702759746041629\n",
      "\n",
      "Epoch 00113: val_binary_accuracy improved from 0.88146 to 0.88151, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 114/300\n",
      "3000/3000 [==============================] - 1810s 603ms/step - loss: 0.2461 - binary_crossentropy: 0.2461 - binary_accuracy: 0.8891 - val_loss: 0.2623 - val_binary_crossentropy: 0.2623 - val_binary_accuracy: 0.8814\n",
      "0.7700457869055518\n",
      "\n",
      "Epoch 00114: val_binary_accuracy did not improve from 0.88151\n",
      "Epoch 115/300\n",
      "3000/3000 [==============================] - 1822s 607ms/step - loss: 0.2466 - binary_crossentropy: 0.2466 - binary_accuracy: 0.8888 - val_loss: 0.2621 - val_binary_crossentropy: 0.2621 - val_binary_accuracy: 0.8815\n",
      "0.7701407640648641\n",
      "\n",
      "Epoch 00115: val_binary_accuracy improved from 0.88151 to 0.88151, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 116/300\n",
      "3000/3000 [==============================] - 1807s 602ms/step - loss: 0.2451 - binary_crossentropy: 0.2451 - binary_accuracy: 0.8897 - val_loss: 0.2622 - val_binary_crossentropy: 0.2622 - val_binary_accuracy: 0.8814\n",
      "0.7702746554769502\n",
      "\n",
      "Epoch 00116: val_binary_accuracy did not improve from 0.88151\n",
      "Epoch 117/300\n",
      "3000/3000 [==============================] - 1802s 601ms/step - loss: 0.2466 - binary_crossentropy: 0.2466 - binary_accuracy: 0.8888 - val_loss: 0.2624 - val_binary_crossentropy: 0.2624 - val_binary_accuracy: 0.8814\n",
      "0.7702594855140045\n",
      "\n",
      "Epoch 00117: val_binary_accuracy did not improve from 0.88151\n",
      "Epoch 118/300\n",
      "3000/3000 [==============================] - 1831s 610ms/step - loss: 0.2470 - binary_crossentropy: 0.2470 - binary_accuracy: 0.8886 - val_loss: 0.2621 - val_binary_crossentropy: 0.2621 - val_binary_accuracy: 0.8815\n",
      "0.7703472074736472\n",
      "\n",
      "Epoch 00118: val_binary_accuracy did not improve from 0.88151\n",
      "Epoch 119/300\n",
      "3000/3000 [==============================] - 1893s 631ms/step - loss: 0.2459 - binary_crossentropy: 0.2459 - binary_accuracy: 0.8893 - val_loss: 0.2620 - val_binary_crossentropy: 0.2620 - val_binary_accuracy: 0.8815\n",
      "0.7703505052916788\n",
      "\n",
      "Epoch 00119: val_binary_accuracy improved from 0.88151 to 0.88155, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 120/300\n",
      "3000/3000 [==============================] - 1841s 614ms/step - loss: 0.2461 - binary_crossentropy: 0.2461 - binary_accuracy: 0.8892 - val_loss: 0.2623 - val_binary_crossentropy: 0.2623 - val_binary_accuracy: 0.8815\n",
      "0.7701730826815746\n",
      "\n",
      "Epoch 00120: val_binary_accuracy did not improve from 0.88155\n",
      "Epoch 121/300\n",
      "3000/3000 [==============================] - 1821s 607ms/step - loss: 0.2462 - binary_crossentropy: 0.2462 - binary_accuracy: 0.8891 - val_loss: 0.2622 - val_binary_crossentropy: 0.2622 - val_binary_accuracy: 0.8814\n",
      "0.7701803378812443\n",
      "\n",
      "Epoch 00121: val_binary_accuracy did not improve from 0.88155\n",
      "Epoch 122/300\n",
      "3000/3000 [==============================] - 1812s 604ms/step - loss: 0.2460 - binary_crossentropy: 0.2460 - binary_accuracy: 0.8892 - val_loss: 0.2623 - val_binary_crossentropy: 0.2623 - val_binary_accuracy: 0.8814\n",
      "0.7700708503225926\n",
      "\n",
      "Epoch 00122: val_binary_accuracy did not improve from 0.88155\n",
      "Epoch 123/300\n",
      "3000/3000 [==============================] - 1855s 618ms/step - loss: 0.2463 - binary_crossentropy: 0.2463 - binary_accuracy: 0.8890 - val_loss: 0.2621 - val_binary_crossentropy: 0.2621 - val_binary_accuracy: 0.8815\n",
      "0.7703768878359323\n",
      "\n",
      "Epoch 00123: val_binary_accuracy did not improve from 0.88155\n",
      "Epoch 124/300\n",
      "3000/3000 [==============================] - 1807s 602ms/step - loss: 0.2460 - binary_crossentropy: 0.2460 - binary_accuracy: 0.8892 - val_loss: 0.2621 - val_binary_crossentropy: 0.2621 - val_binary_accuracy: 0.8814\n",
      "0.7703247823110317\n",
      "\n",
      "Epoch 00124: val_binary_accuracy did not improve from 0.88155\n",
      "Epoch 125/300\n",
      "3000/3000 [==============================] - 1904s 635ms/step - loss: 0.2465 - binary_crossentropy: 0.2465 - binary_accuracy: 0.8888 - val_loss: 0.2623 - val_binary_crossentropy: 0.2623 - val_binary_accuracy: 0.8814\n",
      "0.7702779532949819\n",
      "\n",
      "Epoch 00125: val_binary_accuracy did not improve from 0.88155\n",
      "Epoch 126/300\n",
      "3000/3000 [==============================] - 1827s 609ms/step - loss: 0.2463 - binary_crossentropy: 0.2463 - binary_accuracy: 0.8890 - val_loss: 0.2621 - val_binary_crossentropy: 0.2621 - val_binary_accuracy: 0.8815\n",
      "0.7702106778071357\n",
      "\n",
      "Epoch 00126: val_binary_accuracy did not improve from 0.88155\n",
      "Epoch 127/300\n",
      "3000/3000 [==============================] - 1839s 613ms/step - loss: 0.2465 - binary_crossentropy: 0.2465 - binary_accuracy: 0.8889 - val_loss: 0.2625 - val_binary_crossentropy: 0.2625 - val_binary_accuracy: 0.8813\n",
      "0.7698010888076013\n",
      "\n",
      "Epoch 00127: val_binary_accuracy did not improve from 0.88155\n",
      "Epoch 128/300\n",
      "3000/3000 [==============================] - 1841s 614ms/step - loss: 0.2464 - binary_crossentropy: 0.2464 - binary_accuracy: 0.8889 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8816\n",
      "0.7701849548264886\n",
      "\n",
      "Epoch 00128: val_binary_accuracy improved from 0.88155 to 0.88161, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 129/300\n",
      "3000/3000 [==============================] - 1863s 621ms/step - loss: 0.2460 - binary_crossentropy: 0.2460 - binary_accuracy: 0.8891 - val_loss: 0.2621 - val_binary_crossentropy: 0.2621 - val_binary_accuracy: 0.8815\n",
      "0.770411844707068\n",
      "\n",
      "Epoch 00129: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 130/300\n",
      "3000/3000 [==============================] - 1837s 612ms/step - loss: 0.2464 - binary_crossentropy: 0.2464 - binary_accuracy: 0.8889 - val_loss: 0.2623 - val_binary_crossentropy: 0.2623 - val_binary_accuracy: 0.8814\n",
      "0.769985107053769\n",
      "\n",
      "Epoch 00130: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 131/300\n",
      "3000/3000 [==============================] - 1755s 585ms/step - loss: 0.2464 - binary_crossentropy: 0.2464 - binary_accuracy: 0.8889 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8816\n",
      "0.770401951252973\n",
      "\n",
      "Epoch 00131: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 132/300\n",
      "3000/3000 [==============================] - 1845s 615ms/step - loss: 0.2457 - binary_crossentropy: 0.2457 - binary_accuracy: 0.8893 - val_loss: 0.2620 - val_binary_crossentropy: 0.2620 - val_binary_accuracy: 0.8815\n",
      "0.770399972562154\n",
      "\n",
      "Epoch 00132: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 133/300\n",
      "3000/3000 [==============================] - 1811s 604ms/step - loss: 0.2465 - binary_crossentropy: 0.2465 - binary_accuracy: 0.8889 - val_loss: 0.2621 - val_binary_crossentropy: 0.2621 - val_binary_accuracy: 0.8815\n",
      "0.7701236154110994\n",
      "\n",
      "Epoch 00133: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 134/300\n",
      "3000/3000 [==============================] - 1824s 608ms/step - loss: 0.2463 - binary_crossentropy: 0.2463 - binary_accuracy: 0.8890 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8816\n",
      "0.7704329507424708\n",
      "\n",
      "Epoch 00134: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 135/300\n",
      "3000/3000 [==============================] - 1859s 620ms/step - loss: 0.2465 - binary_crossentropy: 0.2465 - binary_accuracy: 0.8889 - val_loss: 0.2622 - val_binary_crossentropy: 0.2622 - val_binary_accuracy: 0.8813\n",
      "0.7698268117882484\n",
      "\n",
      "Epoch 00135: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 136/300\n",
      "3000/3000 [==============================] - 1806s 602ms/step - loss: 0.2457 - binary_crossentropy: 0.2457 - binary_accuracy: 0.8893 - val_loss: 0.2618 - val_binary_crossentropy: 0.2618 - val_binary_accuracy: 0.8816\n",
      "0.7704890136490092\n",
      "\n",
      "Epoch 00136: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 137/300\n",
      "3000/3000 [==============================] - 1808s 603ms/step - loss: 0.2460 - binary_crossentropy: 0.2460 - binary_accuracy: 0.8892 - val_loss: 0.2622 - val_binary_crossentropy: 0.2622 - val_binary_accuracy: 0.8814\n",
      "0.7702812511130136\n",
      "\n",
      "Epoch 00137: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 138/300\n",
      "3000/3000 [==============================] - 1780s 593ms/step - loss: 0.2455 - binary_crossentropy: 0.2455 - binary_accuracy: 0.8894 - val_loss: 0.2621 - val_binary_crossentropy: 0.2621 - val_binary_accuracy: 0.8815\n",
      "0.7701084454481537\n",
      "\n",
      "Epoch 00138: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 139/300\n",
      "3000/3000 [==============================] - 1805s 602ms/step - loss: 0.2458 - binary_crossentropy: 0.2458 - binary_accuracy: 0.8892 - val_loss: 0.2621 - val_binary_crossentropy: 0.2621 - val_binary_accuracy: 0.8815\n",
      "0.7702700385317058\n",
      "\n",
      "Epoch 00139: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 140/300\n",
      "3000/3000 [==============================] - 1767s 589ms/step - loss: 0.2463 - binary_crossentropy: 0.2463 - binary_accuracy: 0.8890 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8815\n",
      "0.7703788665267512\n",
      "\n",
      "Epoch 00140: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 141/300\n",
      "3000/3000 [==============================] - 1788s 596ms/step - loss: 0.2460 - binary_crossentropy: 0.2460 - binary_accuracy: 0.8891 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8816\n",
      "0.770500226230317\n",
      "\n",
      "Epoch 00141: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 142/300\n",
      "3000/3000 [==============================] - 1817s 606ms/step - loss: 0.2459 - binary_crossentropy: 0.2459 - binary_accuracy: 0.8892 - val_loss: 0.2622 - val_binary_crossentropy: 0.2622 - val_binary_accuracy: 0.8814\n",
      "0.770207379989104\n",
      "\n",
      "Epoch 00142: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 143/300\n",
      "3000/3000 [==============================] - 1779s 593ms/step - loss: 0.2456 - binary_crossentropy: 0.2456 - binary_accuracy: 0.8894 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8816\n",
      "0.7703392927103712\n",
      "\n",
      "Epoch 00143: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 144/300\n",
      "3000/3000 [==============================] - 1845s 615ms/step - loss: 0.2465 - binary_crossentropy: 0.2465 - binary_accuracy: 0.8888 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8816\n",
      "0.7704441633237784\n",
      "\n",
      "Epoch 00144: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 145/300\n",
      "3000/3000 [==============================] - 1853s 618ms/step - loss: 0.2456 - binary_crossentropy: 0.2456 - binary_accuracy: 0.8894 - val_loss: 0.2622 - val_binary_crossentropy: 0.2622 - val_binary_accuracy: 0.8814\n",
      "0.7703155484205431\n",
      "\n",
      "Epoch 00145: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 146/300\n",
      "3000/3000 [==============================] - 1821s 607ms/step - loss: 0.2458 - binary_crossentropy: 0.2458 - binary_accuracy: 0.8892 - val_loss: 0.2622 - val_binary_crossentropy: 0.2622 - val_binary_accuracy: 0.8815\n",
      "0.7702304647153257\n",
      "\n",
      "Epoch 00146: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 147/300\n",
      "3000/3000 [==============================] - 1827s 609ms/step - loss: 0.2458 - binary_crossentropy: 0.2458 - binary_accuracy: 0.8892 - val_loss: 0.2620 - val_binary_crossentropy: 0.2620 - val_binary_accuracy: 0.8815\n",
      "0.7705496935007922\n",
      "\n",
      "Epoch 00147: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 148/300\n",
      "3000/3000 [==============================] - 1891s 630ms/step - loss: 0.2458 - binary_crossentropy: 0.2458 - binary_accuracy: 0.8893 - val_loss: 0.2620 - val_binary_crossentropy: 0.2620 - val_binary_accuracy: 0.8815\n",
      "0.770411844707068\n",
      "\n",
      "Epoch 00148: val_binary_accuracy did not improve from 0.88161\n",
      "Epoch 149/300\n",
      "3000/3000 [==============================] - 1832s 611ms/step - loss: 0.2461 - binary_crossentropy: 0.2461 - binary_accuracy: 0.8890 - val_loss: 0.2618 - val_binary_crossentropy: 0.2618 - val_binary_accuracy: 0.8816\n",
      "0.7705088005571993\n",
      "\n",
      "Epoch 00149: val_binary_accuracy improved from 0.88161 to 0.88161, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 150/300\n",
      "3000/3000 [==============================] - 1866s 622ms/step - loss: 0.2455 - binary_crossentropy: 0.2455 - binary_accuracy: 0.8894 - val_loss: 0.2617 - val_binary_crossentropy: 0.2617 - val_binary_accuracy: 0.8817\n",
      "0.7706426919692855\n",
      "\n",
      "Epoch 00150: val_binary_accuracy improved from 0.88161 to 0.88168, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 151/300\n",
      "3000/3000 [==============================] - 1795s 598ms/step - loss: 0.2455 - binary_crossentropy: 0.2455 - binary_accuracy: 0.8894 - val_loss: 0.2621 - val_binary_crossentropy: 0.2621 - val_binary_accuracy: 0.8815\n",
      "0.7705167153204754\n",
      "\n",
      "Epoch 00151: val_binary_accuracy did not improve from 0.88168\n",
      "Epoch 152/300\n",
      "3000/3000 [==============================] - 1854s 618ms/step - loss: 0.2457 - binary_crossentropy: 0.2457 - binary_accuracy: 0.8893 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8816\n",
      "0.7707429456374484\n",
      "\n",
      "Epoch 00152: val_binary_accuracy did not improve from 0.88168\n",
      "Epoch 153/300\n",
      "3000/3000 [==============================] - 1847s 616ms/step - loss: 0.2450 - binary_crossentropy: 0.2450 - binary_accuracy: 0.8897 - val_loss: 0.2618 - val_binary_crossentropy: 0.2618 - val_binary_accuracy: 0.8816\n",
      "0.7706413728420728\n",
      "\n",
      "Epoch 00153: val_binary_accuracy did not improve from 0.88168\n",
      "Epoch 154/300\n",
      "3000/3000 [==============================] - 1814s 605ms/step - loss: 0.2462 - binary_crossentropy: 0.2462 - binary_accuracy: 0.8890 - val_loss: 0.2618 - val_binary_crossentropy: 0.2618 - val_binary_accuracy: 0.8816\n",
      "0.7706994144394302\n",
      "\n",
      "Epoch 00154: val_binary_accuracy did not improve from 0.88168\n",
      "Epoch 155/300\n",
      "3000/3000 [==============================] - 1790s 597ms/step - loss: 0.2463 - binary_crossentropy: 0.2463 - binary_accuracy: 0.8890 - val_loss: 0.2620 - val_binary_crossentropy: 0.2620 - val_binary_accuracy: 0.8815\n",
      "0.7704553759050862\n",
      "\n",
      "Epoch 00155: val_binary_accuracy did not improve from 0.88168\n",
      "Epoch 156/300\n",
      "   2/3000 [..............................] - ETA: 25:37 - loss: 0.2476 - binary_crossentropy: 0.2476 - binary_accuracy: 0.8885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.600149). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 1829s 610ms/step - loss: 0.2463 - binary_crossentropy: 0.2463 - binary_accuracy: 0.8890 - val_loss: 0.2616 - val_binary_crossentropy: 0.2616 - val_binary_accuracy: 0.8817\n",
      "0.7705602465184935\n",
      "\n",
      "Epoch 00156: val_binary_accuracy improved from 0.88168 to 0.88169, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 157/300\n",
      "3000/3000 [==============================] - 1819s 606ms/step - loss: 0.2462 - binary_crossentropy: 0.2462 - binary_accuracy: 0.8890 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8816\n",
      "0.7704936305942536\n",
      "\n",
      "Epoch 00157: val_binary_accuracy did not improve from 0.88169\n",
      "Epoch 158/300\n",
      "3000/3000 [==============================] - 1799s 600ms/step - loss: 0.2458 - binary_crossentropy: 0.2458 - binary_accuracy: 0.8893 - val_loss: 0.2622 - val_binary_crossentropy: 0.2622 - val_binary_accuracy: 0.8815\n",
      "0.7703551222369232\n",
      "\n",
      "Epoch 00158: val_binary_accuracy did not improve from 0.88169\n",
      "Epoch 159/300\n",
      "3000/3000 [==============================] - 1841s 614ms/step - loss: 0.2458 - binary_crossentropy: 0.2458 - binary_accuracy: 0.8892 - val_loss: 0.2620 - val_binary_crossentropy: 0.2620 - val_binary_accuracy: 0.8816\n",
      "0.7705879481899596\n",
      "\n",
      "Epoch 00159: val_binary_accuracy did not improve from 0.88169\n",
      "Epoch 160/300\n",
      "3000/3000 [==============================] - 1801s 600ms/step - loss: 0.2462 - binary_crossentropy: 0.2462 - binary_accuracy: 0.8890 - val_loss: 0.2615 - val_binary_crossentropy: 0.2615 - val_binary_accuracy: 0.8817\n",
      "0.7706334580787968\n",
      "\n",
      "Epoch 00160: val_binary_accuracy improved from 0.88169 to 0.88173, saving model to Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5\n",
      "Epoch 161/300\n",
      "3000/3000 [==============================] - 1802s 601ms/step - loss: 0.2459 - binary_crossentropy: 0.2459 - binary_accuracy: 0.8892 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8816\n",
      "0.7707079887663126\n",
      "\n",
      "Epoch 00161: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 162/300\n",
      "3000/3000 [==============================] - 1802s 601ms/step - loss: 0.2459 - binary_crossentropy: 0.2459 - binary_accuracy: 0.8892 - val_loss: 0.2620 - val_binary_crossentropy: 0.2620 - val_binary_accuracy: 0.8815\n",
      "0.7706308198243714\n",
      "\n",
      "Epoch 00162: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 163/300\n",
      "3000/3000 [==============================] - 1792s 597ms/step - loss: 0.2449 - binary_crossentropy: 0.2449 - binary_accuracy: 0.8898 - val_loss: 0.2618 - val_binary_crossentropy: 0.2618 - val_binary_accuracy: 0.8816\n",
      "0.7704896732126156\n",
      "\n",
      "Epoch 00163: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 164/300\n",
      "3000/3000 [==============================] - 1833s 611ms/step - loss: 0.2453 - binary_crossentropy: 0.2453 - binary_accuracy: 0.8895 - val_loss: 0.2618 - val_binary_crossentropy: 0.2618 - val_binary_accuracy: 0.8817\n",
      "0.7706703936407515\n",
      "\n",
      "Epoch 00164: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 165/300\n",
      "3000/3000 [==============================] - 1792s 597ms/step - loss: 0.2457 - binary_crossentropy: 0.2457 - binary_accuracy: 0.8893 - val_loss: 0.2620 - val_binary_crossentropy: 0.2620 - val_binary_accuracy: 0.8815\n",
      "0.7704111851434616\n",
      "\n",
      "Epoch 00165: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 166/300\n",
      "3000/3000 [==============================] - 1807s 602ms/step - loss: 0.2462 - binary_crossentropy: 0.2462 - binary_accuracy: 0.8890 - val_loss: 0.2618 - val_binary_crossentropy: 0.2618 - val_binary_accuracy: 0.8816\n",
      "0.7706011394620863\n",
      "\n",
      "Epoch 00166: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 167/300\n",
      "3000/3000 [==============================] - 1787s 596ms/step - loss: 0.2452 - binary_crossentropy: 0.2452 - binary_accuracy: 0.8896 - val_loss: 0.2620 - val_binary_crossentropy: 0.2620 - val_binary_accuracy: 0.8816\n",
      "0.7706506067325615\n",
      "\n",
      "Epoch 00167: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 168/300\n",
      "3000/3000 [==============================] - 1832s 611ms/step - loss: 0.2455 - binary_crossentropy: 0.2455 - binary_accuracy: 0.8894 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8816\n",
      "0.7706367558968285\n",
      "\n",
      "Epoch 00168: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 169/300\n",
      "3000/3000 [==============================] - 1816s 605ms/step - loss: 0.2454 - binary_crossentropy: 0.2454 - binary_accuracy: 0.8894 - val_loss: 0.2618 - val_binary_crossentropy: 0.2618 - val_binary_accuracy: 0.8816\n",
      "0.7706842444764845\n",
      "\n",
      "Epoch 00169: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 170/300\n",
      "3000/3000 [==============================] - 1832s 611ms/step - loss: 0.2453 - binary_crossentropy: 0.2453 - binary_accuracy: 0.8895 - val_loss: 0.2618 - val_binary_crossentropy: 0.2618 - val_binary_accuracy: 0.8816\n",
      "0.7705299065926021\n",
      "\n",
      "Epoch 00170: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 171/300\n",
      "3000/3000 [==============================] - 1777s 592ms/step - loss: 0.2458 - binary_crossentropy: 0.2458 - binary_accuracy: 0.8892 - val_loss: 0.2620 - val_binary_crossentropy: 0.2620 - val_binary_accuracy: 0.8816\n",
      "0.7703399522739774\n",
      "\n",
      "Epoch 00171: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 172/300\n",
      "3000/3000 [==============================] - 1821s 607ms/step - loss: 0.2458 - binary_crossentropy: 0.2458 - binary_accuracy: 0.8892 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8816\n",
      "0.7704527376506608\n",
      "\n",
      "Epoch 00172: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 173/300\n",
      "3000/3000 [==============================] - 1836s 612ms/step - loss: 0.2457 - binary_crossentropy: 0.2457 - binary_accuracy: 0.8892 - val_loss: 0.2617 - val_binary_crossentropy: 0.2617 - val_binary_accuracy: 0.8817\n",
      "0.7706855636036972\n",
      "\n",
      "Epoch 00173: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 174/300\n",
      "3000/3000 [==============================] - 1807s 602ms/step - loss: 0.2453 - binary_crossentropy: 0.2453 - binary_accuracy: 0.8895 - val_loss: 0.2620 - val_binary_crossentropy: 0.2620 - val_binary_accuracy: 0.8815\n",
      "0.7702799319858009\n",
      "\n",
      "Epoch 00174: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 175/300\n",
      "3000/3000 [==============================] - 1815s 605ms/step - loss: 0.2456 - binary_crossentropy: 0.2456 - binary_accuracy: 0.8894 - val_loss: 0.2620 - val_binary_crossentropy: 0.2620 - val_binary_accuracy: 0.8815\n",
      "0.7704989071031043\n",
      "\n",
      "Epoch 00175: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 176/300\n",
      "3000/3000 [==============================] - 1813s 604ms/step - loss: 0.2455 - binary_crossentropy: 0.2455 - binary_accuracy: 0.8894 - val_loss: 0.2617 - val_binary_crossentropy: 0.2617 - val_binary_accuracy: 0.8817\n",
      "0.7706387345876474\n",
      "\n",
      "Epoch 00176: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 177/300\n",
      "3000/3000 [==============================] - 1865s 622ms/step - loss: 0.2453 - binary_crossentropy: 0.2453 - binary_accuracy: 0.8895 - val_loss: 0.2618 - val_binary_crossentropy: 0.2618 - val_binary_accuracy: 0.8817\n",
      "0.7706947974941859\n",
      "\n",
      "Epoch 00177: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 178/300\n",
      "3000/3000 [==============================] - 1811s 604ms/step - loss: 0.2453 - binary_crossentropy: 0.2453 - binary_accuracy: 0.8896 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8817\n",
      "0.7706229050610954\n",
      "\n",
      "Epoch 00178: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 179/300\n",
      "3000/3000 [==============================] - 1841s 614ms/step - loss: 0.2457 - binary_crossentropy: 0.2457 - binary_accuracy: 0.8893 - val_loss: 0.2619 - val_binary_crossentropy: 0.2619 - val_binary_accuracy: 0.8816\n",
      "0.7705628847729189\n",
      "\n",
      "Epoch 00179: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 180/300\n",
      "3000/3000 [==============================] - 1834s 611ms/step - loss: 0.2452 - binary_crossentropy: 0.2452 - binary_accuracy: 0.8896 - val_loss: 0.2618 - val_binary_crossentropy: 0.2618 - val_binary_accuracy: 0.8816\n",
      "0.7703458883464345\n",
      "\n",
      "Epoch 00180: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 181/300\n",
      "3000/3000 [==============================] - 1811s 604ms/step - loss: 0.2467 - binary_crossentropy: 0.2467 - binary_accuracy: 0.8887 - val_loss: 0.2617 - val_binary_crossentropy: 0.2617 - val_binary_accuracy: 0.8817\n",
      "0.7705206727021133\n",
      "\n",
      "Epoch 00181: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 182/300\n",
      "3000/3000 [==============================] - 1832s 611ms/step - loss: 0.2453 - binary_crossentropy: 0.2453 - binary_accuracy: 0.8895 - val_loss: 0.2618 - val_binary_crossentropy: 0.2618 - val_binary_accuracy: 0.8816\n",
      "0.7702739959133439\n",
      "\n",
      "Epoch 00182: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 183/300\n",
      "3000/3000 [==============================] - 1808s 603ms/step - loss: 0.2463 - binary_crossentropy: 0.2463 - binary_accuracy: 0.8890 - val_loss: 0.2620 - val_binary_crossentropy: 0.2620 - val_binary_accuracy: 0.8816\n",
      "0.7703993129985477\n",
      "\n",
      "Epoch 00183: val_binary_accuracy did not improve from 0.88173\n",
      "Epoch 184/300\n",
      "1070/3000 [=========>....................] - ETA: 19:30 - loss: 0.2461 - binary_crossentropy: 0.2461 - binary_accuracy: 0.8891"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b3e220fd760a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    186\u001b[0m model.fit_generator(train_generate(), steps_per_epoch=3000, epochs=300, verbose=1,\n\u001b[1;32m    187\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_q_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                       callbacks = [mstk_ndcg_callback(),reduceLROnPlat,checkpoint])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model Fitting\n",
    "\n",
    "def tile_tile(X):\n",
    "    X = K.tile(X, [1,10,1]) \n",
    "    return X\n",
    "\n",
    "\n",
    "def exp_smooth5(X):   \n",
    "    weight = np.power(0.5,9 - np.arange(10))\n",
    "    weight = weight/np.sum(weight)\n",
    "    weight = np.reshape(weight, (1,10,1))\n",
    "    att_output_weight = K.variable(weight)\n",
    "    print(att_output_weight.shape)\n",
    "    att_output_result = X*att_output_weight    \n",
    "    print(X.shape)\n",
    "    att_output_result = K.mean(att_output_result, axis=1)\n",
    "    \n",
    "    return att_output_result\n",
    "\n",
    "def exp_smooth8(X):   \n",
    "    weight = np.power(0.8,9 - np.arange(10))\n",
    "    weight = weight/np.sum(weight)\n",
    "    weight = np.reshape(weight, (1,10,1))\n",
    "    att_output_weight = K.variable(weight)\n",
    "    print(att_output_weight.shape)\n",
    "    att_output_result = X*att_output_weight    \n",
    "    print(X.shape)\n",
    "    att_output_result = K.mean(att_output_result, axis=1)\n",
    "    \n",
    "    return att_output_result\n",
    "\n",
    "\n",
    "class mstk_ndcg_callback(Callback):\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):      \n",
    "\n",
    "        y_pred = self.model.predict(X_valid,batch_size=800)\n",
    "        \n",
    "        hkl.dump(y_pred, data_path+'y_pred.hkl', mode='w', compression='gzip')\n",
    "        \n",
    "        y_pred = y_pred[:,:,1]\n",
    "        \n",
    "        Y_valid_i = Y_valid[:,:,1]\n",
    "        \n",
    "        Y_pred = 0*y_pred\n",
    "        Y_pred[y_pred>=0.5] = 1\n",
    "        \n",
    "        Y_pred = (Y_pred==Y_valid_i)\n",
    "        \n",
    "        Y_pred = Y_pred[valid_output>=0]\n",
    "        \n",
    "        #print(Y_pred.shape)\n",
    "\n",
    "        print(np.mean(Y_pred))\n",
    "        \n",
    "        #hkl.dump(song_embedding_matrix, data_path+'song_embedding_matrix_80.hkl', mode='w', compression='gzip')\n",
    "\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "\n",
    "def skip_model_5_mtsk_att(cell_size = 350):\n",
    "\n",
    "    input_data_context_id = Input(shape=[10], name=\"context\")\n",
    "    input_data_start_id = Input(shape=[10], name=\"start\")\n",
    "    input_data_end_id = Input(shape=[10], name=\"end\")\n",
    "    input_data = Input(shape=[10,input_fea_dim], name=\"input_fea\")\n",
    "    output_data_i = Input(shape=[10], name=\"output_fea\")\n",
    "    input_id = Input(shape=[10], name=\"input_id\")\n",
    "    output_id = Input(shape=[10], name=\"output_id\")\n",
    "\n",
    "    song_emb_layer = Embedding(\n",
    "        input_dim=spotify_song_array.shape[0],\n",
    "        output_dim=spotify_song_array.shape[1],\n",
    "        weights=[spotify_song_array],\n",
    "        trainable=False\n",
    "    )\n",
    "\n",
    "    context_emb_layer = Embedding(n_context_type,25)\n",
    "    reason_start_emb_layer = Embedding(n_reason_start,25)\n",
    "    reason_end_emb_layer = Embedding(n_reason_end,25)\n",
    "\n",
    "    emb_input_id = song_emb_layer(input_id)\n",
    "    emb_output_id = song_emb_layer(output_id)\n",
    "    emb_input_data_context_id = context_emb_layer(input_data_context_id)\n",
    "    emb_input_data_start_id = reason_start_emb_layer(input_data_start_id)\n",
    "    emb_input_data_end_id = reason_end_emb_layer(input_data_end_id)\n",
    "\n",
    "    input_data_a = concatenate([input_data,emb_input_id,emb_input_data_context_id,\n",
    "                              emb_input_data_start_id,emb_input_data_end_id])\n",
    "\n",
    "    # rnn layers\n",
    "#    encoder_outputs, state_h\n",
    "    \n",
    "    encoder_outputs, rnn_layer = GRU(cell_size, return_sequences=True, return_state=True) (input_data_a)\n",
    "    \n",
    "    encoder_outputs_1, rnn_layer_1 = GRU(cell_size, return_sequences=True, return_state=True) (encoder_outputs)    \n",
    "   \n",
    "    rnn_layer = concatenate([rnn_layer, rnn_layer_1])\n",
    "    \n",
    "    output_data = Reshape([10,1])(output_data_i)\n",
    "    \n",
    "    output_data = concatenate([output_data, emb_output_id])\n",
    "\n",
    "    output_data = Dense(2*cell_size, activation='relu')(output_data)\n",
    "\n",
    "    rnn_layer_multi = Multiply()([output_data, rnn_layer])\n",
    "    \n",
    "    rnn_layer_reshape = Reshape([1,2*cell_size])(rnn_layer)\n",
    "    \n",
    "    rnn_layer_reshape = Lambda(tile_tile)(rnn_layer_reshape)\n",
    "\n",
    "    output_result = concatenate([rnn_layer_reshape, rnn_layer_multi, output_data])\n",
    "    \n",
    "    output_rnn_layer = Bidirectional(GRU(cell_size, return_sequences=True))(output_result)\n",
    "    \n",
    "    output_rnn_layer_2 = Bidirectional(GRU(cell_size, return_sequences=True))(output_rnn_layer)\n",
    "    \n",
    "    output_rnn_layer_3 = Bidirectional(GRU(200, return_sequences=True))(output_rnn_layer_2)\n",
    "    \n",
    "    output_rnn_layer_4 = Bidirectional(GRU(200, return_sequences=True))(output_rnn_layer_3)\n",
    "    \n",
    "    output_result = concatenate([output_result, output_rnn_layer, output_rnn_layer_2, output_rnn_layer_3, output_rnn_layer_4])\n",
    "\n",
    "    output_result = Dense(1000, activation='relu')(output_result)\n",
    "    output_result_1 = Dense(784, activation='relu')(output_result)\n",
    "    #output_result_2 = Dense(784, activation='elu')(output_result_1)\n",
    "    \n",
    "    #output_result = concatenate([output_result, output_result_1, output_result_2])\n",
    "    \n",
    "    output_result = Dropout(0.2)(output_result_1)\n",
    "\n",
    "    output_result = Dense(11, activation='sigmoid')(output_result)\n",
    "    \n",
    "    #output_result = Reshape([10])(output_result)\n",
    "\n",
    "\n",
    "    model = Model(inputs=[input_data_context_id, input_data_start_id,\n",
    "                          input_data_end_id, input_data, output_data_i, input_id, output_id], outputs=output_result)\n",
    "\n",
    "    sgd = Adam(lr=0.0008)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['binary_crossentropy', 'binary_accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "checkpoint = ModelCheckpoint('Data/skip_net_glove_max_mtsk_more_layer_best_v6.hdf5', monitor='val_binary_accuracy', verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "#K.clear_session()\n",
    "\n",
    "model = skip_model_5_mtsk_att()\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=4, \n",
    "                                   verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\n",
    "\n",
    "model.fit_generator(train_generate(), steps_per_epoch=3000, epochs=300, verbose=1,\n",
    "                        validation_data=(X_valid,Y_valid),max_q_size=35,\n",
    "                      callbacks = [mstk_ndcg_callback(),reduceLROnPlat,checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
